{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Analisis Sentimen Warna** \\\n",
        "Model ini adalah versi lain dari Color_Sentiment_2.ipynb. Untuk mendapatkan output lima warna sekaligus, dibuat lima model dengan setiap model dilatih menggunakan tiap kolom label dari dataset (hex_1, hex_2, hex_3, hex_4, hex_5)."
      ],
      "metadata": {
        "id": "7zbQHepm0my0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EhxSVPJRpfVq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "81ffa340-76f0-440e-c14b-b47fe954d431"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         text    hex_1    hex_2    hex_3  \\\n",
              "0            aku ingin warna yang menenangkan  #87CEEB  #B0E2FF  #C6E2B3   \n",
              "1           pilih warna yang membuatku rileks  #98FB98  #C4FFB2  #D5FFCC   \n",
              "2             aku suka warna-warna yang cerah  #FFFF00  #FFFF80  #FFFF33   \n",
              "3             cari warna yang terlihat elegan  #800080  #A85CA0  #B37CB3   \n",
              "4           warna yang memberikan kesan alami  #008000  #00A600  #00CC00   \n",
              "..                                        ...      ...      ...      ...   \n",
              "219               aku pengen warna yang segar  #00FFC8  #32FFD5  #64FFE2   \n",
              "220  pilih warna yang cocok untuk kamar tidur  #003366  #004073  #004D80   \n",
              "221               warna yang menyegarkan mata  #00FF00  #2AFF2A  #55FF55   \n",
              "222           aku suka warna-warna yang cerah  #FFFF00  #FFFF33  #FFFF66   \n",
              "223           cari warna yang terlihat elegan  #800080  #960096  #AC00AC   \n",
              "\n",
              "       hex_4    hex_5  \n",
              "0    #9BBF96  #5E99D4  \n",
              "1    #B2F0C3  #7DFD92  \n",
              "2    #FFEB3B  #FFF44F  \n",
              "3    #8B4F8B  #673567  \n",
              "4    #008C00  #005C00  \n",
              "..       ...      ...  \n",
              "219  #96FFEF  #C8FFFC  \n",
              "220  #00588D  #00639A  \n",
              "221  #7FFF7F  #AAFFAA  \n",
              "222  #FFFF99  #FFFFCC  \n",
              "223  #C200C2  #D800D8  \n",
              "\n",
              "[224 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12dd3f4a-a9a5-46fa-a0e6-91bd43f999d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hex_1</th>\n",
              "      <th>hex_2</th>\n",
              "      <th>hex_3</th>\n",
              "      <th>hex_4</th>\n",
              "      <th>hex_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aku ingin warna yang menenangkan</td>\n",
              "      <td>#87CEEB</td>\n",
              "      <td>#B0E2FF</td>\n",
              "      <td>#C6E2B3</td>\n",
              "      <td>#9BBF96</td>\n",
              "      <td>#5E99D4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pilih warna yang membuatku rileks</td>\n",
              "      <td>#98FB98</td>\n",
              "      <td>#C4FFB2</td>\n",
              "      <td>#D5FFCC</td>\n",
              "      <td>#B2F0C3</td>\n",
              "      <td>#7DFD92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aku suka warna-warna yang cerah</td>\n",
              "      <td>#FFFF00</td>\n",
              "      <td>#FFFF80</td>\n",
              "      <td>#FFFF33</td>\n",
              "      <td>#FFEB3B</td>\n",
              "      <td>#FFF44F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cari warna yang terlihat elegan</td>\n",
              "      <td>#800080</td>\n",
              "      <td>#A85CA0</td>\n",
              "      <td>#B37CB3</td>\n",
              "      <td>#8B4F8B</td>\n",
              "      <td>#673567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>warna yang memberikan kesan alami</td>\n",
              "      <td>#008000</td>\n",
              "      <td>#00A600</td>\n",
              "      <td>#00CC00</td>\n",
              "      <td>#008C00</td>\n",
              "      <td>#005C00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>aku pengen warna yang segar</td>\n",
              "      <td>#00FFC8</td>\n",
              "      <td>#32FFD5</td>\n",
              "      <td>#64FFE2</td>\n",
              "      <td>#96FFEF</td>\n",
              "      <td>#C8FFFC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>pilih warna yang cocok untuk kamar tidur</td>\n",
              "      <td>#003366</td>\n",
              "      <td>#004073</td>\n",
              "      <td>#004D80</td>\n",
              "      <td>#00588D</td>\n",
              "      <td>#00639A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>warna yang menyegarkan mata</td>\n",
              "      <td>#00FF00</td>\n",
              "      <td>#2AFF2A</td>\n",
              "      <td>#55FF55</td>\n",
              "      <td>#7FFF7F</td>\n",
              "      <td>#AAFFAA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>aku suka warna-warna yang cerah</td>\n",
              "      <td>#FFFF00</td>\n",
              "      <td>#FFFF33</td>\n",
              "      <td>#FFFF66</td>\n",
              "      <td>#FFFF99</td>\n",
              "      <td>#FFFFCC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>cari warna yang terlihat elegan</td>\n",
              "      <td>#800080</td>\n",
              "      <td>#960096</td>\n",
              "      <td>#AC00AC</td>\n",
              "      <td>#C200C2</td>\n",
              "      <td>#D800D8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>224 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12dd3f4a-a9a5-46fa-a0e6-91bd43f999d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12dd3f4a-a9a5-46fa-a0e6-91bd43f999d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12dd3f4a-a9a5-46fa-a0e6-91bd43f999d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(\"./color_dataset2.csv\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['text'] = dataset['text'].str.lower()\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "NgaAtcIx-l4t",
        "outputId": "286c5161-b55e-4bc7-fab4-cad00ff15f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                text    hex_1    hex_2    hex_3    hex_4  \\\n",
              "0   aku ingin warna yang menenangkan  #87CEEB  #B0E2FF  #C6E2B3  #9BBF96   \n",
              "1  pilih warna yang membuatku rileks  #98FB98  #C4FFB2  #D5FFCC  #B2F0C3   \n",
              "2    aku suka warna-warna yang cerah  #FFFF00  #FFFF80  #FFFF33  #FFEB3B   \n",
              "3    cari warna yang terlihat elegan  #800080  #A85CA0  #B37CB3  #8B4F8B   \n",
              "4  warna yang memberikan kesan alami  #008000  #00A600  #00CC00  #008C00   \n",
              "\n",
              "     hex_5  \n",
              "0  #5E99D4  \n",
              "1  #7DFD92  \n",
              "2  #FFF44F  \n",
              "3  #673567  \n",
              "4  #005C00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40dd6af0-7b40-40bf-8ce1-ba91daa689ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hex_1</th>\n",
              "      <th>hex_2</th>\n",
              "      <th>hex_3</th>\n",
              "      <th>hex_4</th>\n",
              "      <th>hex_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aku ingin warna yang menenangkan</td>\n",
              "      <td>#87CEEB</td>\n",
              "      <td>#B0E2FF</td>\n",
              "      <td>#C6E2B3</td>\n",
              "      <td>#9BBF96</td>\n",
              "      <td>#5E99D4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pilih warna yang membuatku rileks</td>\n",
              "      <td>#98FB98</td>\n",
              "      <td>#C4FFB2</td>\n",
              "      <td>#D5FFCC</td>\n",
              "      <td>#B2F0C3</td>\n",
              "      <td>#7DFD92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aku suka warna-warna yang cerah</td>\n",
              "      <td>#FFFF00</td>\n",
              "      <td>#FFFF80</td>\n",
              "      <td>#FFFF33</td>\n",
              "      <td>#FFEB3B</td>\n",
              "      <td>#FFF44F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cari warna yang terlihat elegan</td>\n",
              "      <td>#800080</td>\n",
              "      <td>#A85CA0</td>\n",
              "      <td>#B37CB3</td>\n",
              "      <td>#8B4F8B</td>\n",
              "      <td>#673567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>warna yang memberikan kesan alami</td>\n",
              "      <td>#008000</td>\n",
              "      <td>#00A600</td>\n",
              "      <td>#00CC00</td>\n",
              "      <td>#008C00</td>\n",
              "      <td>#005C00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40dd6af0-7b40-40bf-8ce1-ba91daa689ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40dd6af0-7b40-40bf-8ce1-ba91daa689ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40dd6af0-7b40-40bf-8ce1-ba91daa689ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = dataset['text']\n",
        "\n",
        "label1dic = {}\n",
        "for x in dataset['hex_1']:\n",
        "     if x not in label1dic:\n",
        "         label1dic[x] = len(label1dic)\n",
        "label1 = [label1dic[x] for x in dataset['hex_1']]\n",
        "label1dic = dict((v, k) for k, v in label1dic.items())\n",
        "\n",
        "label2dic = {}\n",
        "for x in dataset['hex_2']:\n",
        "     if x not in label2dic:\n",
        "         label2dic[x] = len(label2dic)\n",
        "label2 = [label2dic[x] for x in dataset['hex_2']]\n",
        "label2dic = dict((v, k) for k, v in label2dic.items())\n",
        "\n",
        "label3dic = {}\n",
        "for x in dataset['hex_3']:\n",
        "     if x not in label3dic:\n",
        "         label3dic[x] = len(label3dic)\n",
        "label3 = [label3dic[x] for x in dataset['hex_3']]\n",
        "label3dic = dict((v, k) for k, v in label3dic.items())\n",
        "\n",
        "label4dic = {}\n",
        "for x in dataset['hex_4']:\n",
        "     if x not in label4dic:\n",
        "         label4dic[x] = len(label4dic)\n",
        "label4 = [label4dic[x] for x in dataset['hex_4']]\n",
        "label4dic = dict((v, k) for k, v in label4dic.items())\n",
        "\n",
        "label5dic = {}\n",
        "for x in dataset['hex_5']:\n",
        "     if x not in label5dic:\n",
        "         label5dic[x] = len(label5dic)\n",
        "label5 = [label5dic[x] for x in dataset['hex_5']]\n",
        "label5dic = dict((v, k) for k, v in label5dic.items())\n",
        "\n",
        "training_size = 170\n",
        "\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "training_labels1 = label1[0:training_size]\n",
        "testing_labels1 = label1[training_size:]\n",
        "\n",
        "training_labels2 = label2[0:training_size]\n",
        "testing_labels2 = label2[training_size:]\n",
        "\n",
        "training_labels3 = label3[0:training_size]\n",
        "testing_labels3 = label3[training_size:]\n",
        "\n",
        "training_labels4 = label4[0:training_size]\n",
        "testing_labels4 = label4[training_size:]\n",
        "\n",
        "training_labels5 = label5[0:training_size]\n",
        "testing_labels5 = label5[training_size:]\n"
      ],
      "metadata": {
        "id": "-YasHif0qKOh"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "vocab_size = 1000\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "training_labels1 = np.array(training_labels1)\n",
        "testing_labels1 = np.array(testing_labels1)\n",
        "\n",
        "training_labels2 = np.array(training_labels2)\n",
        "testing_labels2 = np.array(testing_labels2)\n",
        "\n",
        "training_labels3 = np.array(training_labels3)\n",
        "testing_labels3 = np.array(testing_labels3)\n",
        "\n",
        "training_labels4 = np.array(training_labels4)\n",
        "testing_labels4 = np.array(testing_labels4)\n",
        "\n",
        "training_labels5 = np.array(training_labels5)\n",
        "testing_labels5 = np.array(testing_labels5)"
      ],
      "metadata": {
        "id": "fn85pRkTuvsA"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "embedding_dim = 16\n",
        "lstm_dim = 32\n",
        "dense_dim = 24\n",
        "\n",
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_dim)),\n",
        "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(np.unique(label1).size, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_dim)),\n",
        "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(np.unique(label2).size, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_dim)),\n",
        "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(np.unique(label3).size, activation='softmax')\n",
        "])\n",
        "\n",
        "model3.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_dim)),\n",
        "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(np.unique(label4).size, activation='softmax')\n",
        "])\n",
        "\n",
        "model4.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_dim)),\n",
        "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(np.unique(label5).size, activation='softmax')\n",
        "])\n",
        "\n",
        "model5.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "BXKU4fIxu11F"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 150\n",
        "\n",
        "history_lstm1 = model1.fit(training_padded, training_labels1, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYrRk9Grvs14",
        "outputId": "df4208cf-41bf-47d2-d1a8-a41f6338b399"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "6/6 [==============================] - 2s 453ms/step - loss: 3.5702 - accuracy: 0.0353 - val_loss: 3.5490 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 3.5525 - accuracy: 0.0235 - val_loss: 3.5159 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.5293 - accuracy: 0.0412 - val_loss: 3.4500 - val_accuracy: 0.1111\n",
            "Epoch 4/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.4844 - accuracy: 0.0647 - val_loss: 3.3781 - val_accuracy: 0.1111\n",
            "Epoch 5/150\n",
            "6/6 [==============================] - 1s 112ms/step - loss: 3.4564 - accuracy: 0.0647 - val_loss: 3.3364 - val_accuracy: 0.1111\n",
            "Epoch 6/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.4354 - accuracy: 0.0647 - val_loss: 3.3161 - val_accuracy: 0.1111\n",
            "Epoch 7/150\n",
            "6/6 [==============================] - 1s 113ms/step - loss: 3.4066 - accuracy: 0.0647 - val_loss: 3.2900 - val_accuracy: 0.1111\n",
            "Epoch 8/150\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 3.3855 - accuracy: 0.0647 - val_loss: 3.2559 - val_accuracy: 0.1111\n",
            "Epoch 9/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.3658 - accuracy: 0.0647 - val_loss: 3.2195 - val_accuracy: 0.1111\n",
            "Epoch 10/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 3.3496 - accuracy: 0.0647 - val_loss: 3.1987 - val_accuracy: 0.1111\n",
            "Epoch 11/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 3.3294 - accuracy: 0.0647 - val_loss: 3.1965 - val_accuracy: 0.1111\n",
            "Epoch 12/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 3.3161 - accuracy: 0.0647 - val_loss: 3.1764 - val_accuracy: 0.1111\n",
            "Epoch 13/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 3.3005 - accuracy: 0.1059 - val_loss: 3.1631 - val_accuracy: 0.2222\n",
            "Epoch 14/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 3.2823 - accuracy: 0.1353 - val_loss: 3.1385 - val_accuracy: 0.2037\n",
            "Epoch 15/150\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 3.2622 - accuracy: 0.1294 - val_loss: 3.1033 - val_accuracy: 0.3333\n",
            "Epoch 16/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 3.2401 - accuracy: 0.1765 - val_loss: 3.0629 - val_accuracy: 0.2593\n",
            "Epoch 17/150\n",
            "6/6 [==============================] - 1s 180ms/step - loss: 3.2032 - accuracy: 0.1588 - val_loss: 2.9890 - val_accuracy: 0.2593\n",
            "Epoch 18/150\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 3.1554 - accuracy: 0.1882 - val_loss: 2.9702 - val_accuracy: 0.3519\n",
            "Epoch 19/150\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 3.1411 - accuracy: 0.2176 - val_loss: 2.8821 - val_accuracy: 0.4444\n",
            "Epoch 20/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 3.0733 - accuracy: 0.2471 - val_loss: 2.8123 - val_accuracy: 0.2593\n",
            "Epoch 21/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 3.0102 - accuracy: 0.1882 - val_loss: 2.7844 - val_accuracy: 0.3519\n",
            "Epoch 22/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.0007 - accuracy: 0.2235 - val_loss: 2.7128 - val_accuracy: 0.3889\n",
            "Epoch 23/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.9178 - accuracy: 0.2412 - val_loss: 2.6071 - val_accuracy: 0.3519\n",
            "Epoch 24/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 2.8472 - accuracy: 0.2353 - val_loss: 2.5874 - val_accuracy: 0.2593\n",
            "Epoch 25/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.8266 - accuracy: 0.2235 - val_loss: 2.5521 - val_accuracy: 0.3704\n",
            "Epoch 26/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.7875 - accuracy: 0.2294 - val_loss: 2.4437 - val_accuracy: 0.3704\n",
            "Epoch 27/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.6896 - accuracy: 0.2529 - val_loss: 2.3445 - val_accuracy: 0.3704\n",
            "Epoch 28/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 2.6300 - accuracy: 0.2588 - val_loss: 2.2727 - val_accuracy: 0.3889\n",
            "Epoch 29/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.5596 - accuracy: 0.2824 - val_loss: 2.2362 - val_accuracy: 0.3889\n",
            "Epoch 30/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.5046 - accuracy: 0.3000 - val_loss: 2.1586 - val_accuracy: 0.4074\n",
            "Epoch 31/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.4420 - accuracy: 0.3059 - val_loss: 2.1436 - val_accuracy: 0.4074\n",
            "Epoch 32/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.3839 - accuracy: 0.3059 - val_loss: 2.3241 - val_accuracy: 0.3889\n",
            "Epoch 33/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.4214 - accuracy: 0.3176 - val_loss: 2.0869 - val_accuracy: 0.4444\n",
            "Epoch 34/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.3315 - accuracy: 0.3412 - val_loss: 2.0207 - val_accuracy: 0.5000\n",
            "Epoch 35/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.2687 - accuracy: 0.3765 - val_loss: 2.0883 - val_accuracy: 0.4444\n",
            "Epoch 36/150\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 2.3264 - accuracy: 0.3824 - val_loss: 1.9392 - val_accuracy: 0.5185\n",
            "Epoch 37/150\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 2.1896 - accuracy: 0.4000 - val_loss: 1.8454 - val_accuracy: 0.5926\n",
            "Epoch 38/150\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 2.1185 - accuracy: 0.4353 - val_loss: 1.7921 - val_accuracy: 0.5926\n",
            "Epoch 39/150\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 2.0636 - accuracy: 0.4353 - val_loss: 1.7397 - val_accuracy: 0.5556\n",
            "Epoch 40/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 2.0046 - accuracy: 0.4000 - val_loss: 1.7006 - val_accuracy: 0.5741\n",
            "Epoch 41/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.9562 - accuracy: 0.4529 - val_loss: 1.6659 - val_accuracy: 0.6296\n",
            "Epoch 42/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.9277 - accuracy: 0.4941 - val_loss: 1.6619 - val_accuracy: 0.6667\n",
            "Epoch 43/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.9109 - accuracy: 0.4765 - val_loss: 1.6573 - val_accuracy: 0.6481\n",
            "Epoch 44/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.8354 - accuracy: 0.5176 - val_loss: 1.5367 - val_accuracy: 0.6481\n",
            "Epoch 45/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.7754 - accuracy: 0.4941 - val_loss: 1.4880 - val_accuracy: 0.6667\n",
            "Epoch 46/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.7268 - accuracy: 0.5647 - val_loss: 1.4360 - val_accuracy: 0.6852\n",
            "Epoch 47/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.6713 - accuracy: 0.5294 - val_loss: 1.4066 - val_accuracy: 0.6852\n",
            "Epoch 48/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.6305 - accuracy: 0.5471 - val_loss: 1.3718 - val_accuracy: 0.6667\n",
            "Epoch 49/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 1.5883 - accuracy: 0.5941 - val_loss: 1.3331 - val_accuracy: 0.7037\n",
            "Epoch 50/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.5393 - accuracy: 0.5882 - val_loss: 1.3015 - val_accuracy: 0.7222\n",
            "Epoch 51/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.4954 - accuracy: 0.6353 - val_loss: 1.2865 - val_accuracy: 0.7037\n",
            "Epoch 52/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 1.4718 - accuracy: 0.6412 - val_loss: 1.2416 - val_accuracy: 0.7037\n",
            "Epoch 53/150\n",
            "6/6 [==============================] - 1s 112ms/step - loss: 1.4448 - accuracy: 0.6529 - val_loss: 1.2003 - val_accuracy: 0.7037\n",
            "Epoch 54/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.4048 - accuracy: 0.6235 - val_loss: 1.1860 - val_accuracy: 0.7037\n",
            "Epoch 55/150\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 1.3776 - accuracy: 0.6412 - val_loss: 1.1812 - val_accuracy: 0.6852\n",
            "Epoch 56/150\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 1.3426 - accuracy: 0.6235 - val_loss: 1.1569 - val_accuracy: 0.7037\n",
            "Epoch 57/150\n",
            "6/6 [==============================] - 1s 181ms/step - loss: 1.3124 - accuracy: 0.6471 - val_loss: 1.1249 - val_accuracy: 0.7407\n",
            "Epoch 58/150\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 1.2774 - accuracy: 0.6765 - val_loss: 1.1247 - val_accuracy: 0.7037\n",
            "Epoch 59/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.2369 - accuracy: 0.6706 - val_loss: 1.0822 - val_accuracy: 0.7222\n",
            "Epoch 60/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.2130 - accuracy: 0.6706 - val_loss: 1.0575 - val_accuracy: 0.7222\n",
            "Epoch 61/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.1799 - accuracy: 0.6824 - val_loss: 1.0390 - val_accuracy: 0.7222\n",
            "Epoch 62/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 1.1420 - accuracy: 0.6824 - val_loss: 0.9809 - val_accuracy: 0.7222\n",
            "Epoch 63/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.1227 - accuracy: 0.6824 - val_loss: 0.9662 - val_accuracy: 0.7407\n",
            "Epoch 64/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 1.0947 - accuracy: 0.7000 - val_loss: 0.9786 - val_accuracy: 0.7222\n",
            "Epoch 65/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.0670 - accuracy: 0.7000 - val_loss: 0.9498 - val_accuracy: 0.7222\n",
            "Epoch 66/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 1.0375 - accuracy: 0.6824 - val_loss: 0.9226 - val_accuracy: 0.7407\n",
            "Epoch 67/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.0218 - accuracy: 0.6882 - val_loss: 0.8888 - val_accuracy: 0.7407\n",
            "Epoch 68/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 0.9971 - accuracy: 0.6941 - val_loss: 0.8741 - val_accuracy: 0.7222\n",
            "Epoch 69/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.9683 - accuracy: 0.7118 - val_loss: 0.8495 - val_accuracy: 0.7407\n",
            "Epoch 70/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.9490 - accuracy: 0.7235 - val_loss: 0.8331 - val_accuracy: 0.7407\n",
            "Epoch 71/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 0.9432 - accuracy: 0.7118 - val_loss: 0.8370 - val_accuracy: 0.7778\n",
            "Epoch 72/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.9171 - accuracy: 0.7412 - val_loss: 0.8091 - val_accuracy: 0.7593\n",
            "Epoch 73/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 0.8930 - accuracy: 0.7471 - val_loss: 0.7774 - val_accuracy: 0.7778\n",
            "Epoch 74/150\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 0.8768 - accuracy: 0.7353 - val_loss: 0.7578 - val_accuracy: 0.7778\n",
            "Epoch 75/150\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 0.8455 - accuracy: 0.7529 - val_loss: 0.7719 - val_accuracy: 0.7778\n",
            "Epoch 76/150\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 0.8343 - accuracy: 0.7353 - val_loss: 0.7310 - val_accuracy: 0.7593\n",
            "Epoch 77/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 0.8337 - accuracy: 0.7235 - val_loss: 0.7240 - val_accuracy: 0.7963\n",
            "Epoch 78/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.8183 - accuracy: 0.7353 - val_loss: 0.7273 - val_accuracy: 0.7963\n",
            "Epoch 79/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 0.8115 - accuracy: 0.7471 - val_loss: 0.7151 - val_accuracy: 0.7963\n",
            "Epoch 80/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 0.7971 - accuracy: 0.7824 - val_loss: 0.7123 - val_accuracy: 0.8148\n",
            "Epoch 81/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 0.7695 - accuracy: 0.7765 - val_loss: 0.6904 - val_accuracy: 0.7963\n",
            "Epoch 82/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.7478 - accuracy: 0.7824 - val_loss: 0.7050 - val_accuracy: 0.7963\n",
            "Epoch 83/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.7311 - accuracy: 0.7882 - val_loss: 0.6878 - val_accuracy: 0.7778\n",
            "Epoch 84/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.7333 - accuracy: 0.7824 - val_loss: 0.6431 - val_accuracy: 0.8148\n",
            "Epoch 85/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.7135 - accuracy: 0.8059 - val_loss: 0.6502 - val_accuracy: 0.8148\n",
            "Epoch 86/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 0.6941 - accuracy: 0.8235 - val_loss: 0.6236 - val_accuracy: 0.7963\n",
            "Epoch 87/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.6737 - accuracy: 0.8118 - val_loss: 0.6158 - val_accuracy: 0.7963\n",
            "Epoch 88/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.6576 - accuracy: 0.8235 - val_loss: 0.6185 - val_accuracy: 0.7963\n",
            "Epoch 89/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.6481 - accuracy: 0.8000 - val_loss: 0.5927 - val_accuracy: 0.7963\n",
            "Epoch 90/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.6321 - accuracy: 0.8176 - val_loss: 0.5905 - val_accuracy: 0.8148\n",
            "Epoch 91/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.6177 - accuracy: 0.8000 - val_loss: 0.5735 - val_accuracy: 0.8333\n",
            "Epoch 92/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.6029 - accuracy: 0.8235 - val_loss: 0.5654 - val_accuracy: 0.8333\n",
            "Epoch 93/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 0.5962 - accuracy: 0.8059 - val_loss: 0.5757 - val_accuracy: 0.8148\n",
            "Epoch 94/150\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 0.5877 - accuracy: 0.8176 - val_loss: 0.5603 - val_accuracy: 0.8148\n",
            "Epoch 95/150\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 0.5852 - accuracy: 0.8294 - val_loss: 0.5713 - val_accuracy: 0.8148\n",
            "Epoch 96/150\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 0.5766 - accuracy: 0.8471 - val_loss: 0.5448 - val_accuracy: 0.7963\n",
            "Epoch 97/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 0.5536 - accuracy: 0.8412 - val_loss: 0.5177 - val_accuracy: 0.8333\n",
            "Epoch 98/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 0.5424 - accuracy: 0.8412 - val_loss: 0.4880 - val_accuracy: 0.8519\n",
            "Epoch 99/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 0.5335 - accuracy: 0.8588 - val_loss: 0.5026 - val_accuracy: 0.8519\n",
            "Epoch 100/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.5348 - accuracy: 0.8588 - val_loss: 0.4691 - val_accuracy: 0.8704\n",
            "Epoch 101/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.5247 - accuracy: 0.8471 - val_loss: 0.4945 - val_accuracy: 0.8148\n",
            "Epoch 102/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.5223 - accuracy: 0.8647 - val_loss: 0.4935 - val_accuracy: 0.8148\n",
            "Epoch 103/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.5093 - accuracy: 0.8647 - val_loss: 0.4984 - val_accuracy: 0.8704\n",
            "Epoch 104/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.4976 - accuracy: 0.8706 - val_loss: 0.5197 - val_accuracy: 0.8519\n",
            "Epoch 105/150\n",
            "6/6 [==============================] - 1s 114ms/step - loss: 0.4847 - accuracy: 0.8824 - val_loss: 0.4890 - val_accuracy: 0.8519\n",
            "Epoch 106/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 0.4729 - accuracy: 0.8882 - val_loss: 0.4887 - val_accuracy: 0.8333\n",
            "Epoch 107/150\n",
            "6/6 [==============================] - 1s 113ms/step - loss: 0.4912 - accuracy: 0.8647 - val_loss: 0.4577 - val_accuracy: 0.8333\n",
            "Epoch 108/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.4896 - accuracy: 0.8706 - val_loss: 0.4988 - val_accuracy: 0.8519\n",
            "Epoch 109/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 0.4824 - accuracy: 0.8647 - val_loss: 0.4548 - val_accuracy: 0.8519\n",
            "Epoch 110/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.4911 - accuracy: 0.8647 - val_loss: 0.4388 - val_accuracy: 0.8889\n",
            "Epoch 111/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.4516 - accuracy: 0.8706 - val_loss: 0.4540 - val_accuracy: 0.8519\n",
            "Epoch 112/150\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 0.4412 - accuracy: 0.8824 - val_loss: 0.4420 - val_accuracy: 0.8148\n",
            "Epoch 113/150\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.4373 - accuracy: 0.8706 - val_loss: 0.4255 - val_accuracy: 0.8519\n",
            "Epoch 114/150\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 0.4249 - accuracy: 0.8824 - val_loss: 0.4306 - val_accuracy: 0.8519\n",
            "Epoch 115/150\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 0.4622 - accuracy: 0.8706 - val_loss: 0.4483 - val_accuracy: 0.8889\n",
            "Epoch 116/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 0.4432 - accuracy: 0.8882 - val_loss: 0.4269 - val_accuracy: 0.8519\n",
            "Epoch 117/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 0.4251 - accuracy: 0.8765 - val_loss: 0.4264 - val_accuracy: 0.8704\n",
            "Epoch 118/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 0.4100 - accuracy: 0.9059 - val_loss: 0.4319 - val_accuracy: 0.8704\n",
            "Epoch 119/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.4060 - accuracy: 0.9000 - val_loss: 0.4269 - val_accuracy: 0.8519\n",
            "Epoch 120/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.3998 - accuracy: 0.9000 - val_loss: 0.4184 - val_accuracy: 0.8519\n",
            "Epoch 121/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.4051 - accuracy: 0.8706 - val_loss: 0.4050 - val_accuracy: 0.8704\n",
            "Epoch 122/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.3918 - accuracy: 0.9059 - val_loss: 0.3955 - val_accuracy: 0.8889\n",
            "Epoch 123/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 0.3903 - accuracy: 0.8706 - val_loss: 0.3938 - val_accuracy: 0.9074\n",
            "Epoch 124/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.3787 - accuracy: 0.9059 - val_loss: 0.3785 - val_accuracy: 0.8889\n",
            "Epoch 125/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.3711 - accuracy: 0.9000 - val_loss: 0.3809 - val_accuracy: 0.8704\n",
            "Epoch 126/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 0.3690 - accuracy: 0.8882 - val_loss: 0.4050 - val_accuracy: 0.8519\n",
            "Epoch 127/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.3708 - accuracy: 0.8941 - val_loss: 0.3946 - val_accuracy: 0.8519\n",
            "Epoch 128/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.3838 - accuracy: 0.8882 - val_loss: 0.3945 - val_accuracy: 0.9074\n",
            "Epoch 129/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.3874 - accuracy: 0.8824 - val_loss: 0.3849 - val_accuracy: 0.8889\n",
            "Epoch 130/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 0.3721 - accuracy: 0.8824 - val_loss: 0.3792 - val_accuracy: 0.8519\n",
            "Epoch 131/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.3564 - accuracy: 0.9118 - val_loss: 0.3656 - val_accuracy: 0.8889\n",
            "Epoch 132/150\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 0.3561 - accuracy: 0.8882 - val_loss: 0.3543 - val_accuracy: 0.9074\n",
            "Epoch 133/150\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 0.3424 - accuracy: 0.9059 - val_loss: 0.3563 - val_accuracy: 0.9074\n",
            "Epoch 134/150\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 0.3432 - accuracy: 0.8882 - val_loss: 0.3385 - val_accuracy: 0.9074\n",
            "Epoch 135/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.3348 - accuracy: 0.9059 - val_loss: 0.3386 - val_accuracy: 0.9074\n",
            "Epoch 136/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.3318 - accuracy: 0.9059 - val_loss: 0.3472 - val_accuracy: 0.8704\n",
            "Epoch 137/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.3303 - accuracy: 0.9000 - val_loss: 0.3360 - val_accuracy: 0.8704\n",
            "Epoch 138/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 0.3248 - accuracy: 0.9059 - val_loss: 0.3489 - val_accuracy: 0.8519\n",
            "Epoch 139/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 0.3264 - accuracy: 0.9000 - val_loss: 0.3525 - val_accuracy: 0.8704\n",
            "Epoch 140/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 0.3203 - accuracy: 0.9000 - val_loss: 0.3452 - val_accuracy: 0.8519\n",
            "Epoch 141/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 0.3223 - accuracy: 0.8941 - val_loss: 0.3419 - val_accuracy: 0.8704\n",
            "Epoch 142/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.3124 - accuracy: 0.9000 - val_loss: 0.3197 - val_accuracy: 0.8704\n",
            "Epoch 143/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.3136 - accuracy: 0.9118 - val_loss: 0.3149 - val_accuracy: 0.8889\n",
            "Epoch 144/150\n",
            "6/6 [==============================] - 1s 113ms/step - loss: 0.3146 - accuracy: 0.8941 - val_loss: 0.3110 - val_accuracy: 0.8889\n",
            "Epoch 145/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.3103 - accuracy: 0.9000 - val_loss: 0.3379 - val_accuracy: 0.8519\n",
            "Epoch 146/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.3097 - accuracy: 0.8882 - val_loss: 0.3490 - val_accuracy: 0.8519\n",
            "Epoch 147/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.3095 - accuracy: 0.9000 - val_loss: 0.3517 - val_accuracy: 0.8704\n",
            "Epoch 148/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 0.2996 - accuracy: 0.9059 - val_loss: 0.3412 - val_accuracy: 0.8704\n",
            "Epoch 149/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.2995 - accuracy: 0.9059 - val_loss: 0.3347 - val_accuracy: 0.8704\n",
            "Epoch 150/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 0.3064 - accuracy: 0.8765 - val_loss: 0.3301 - val_accuracy: 0.8704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm2 = model2.fit(training_padded, training_labels2, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIFIjjTuzLAx",
        "outputId": "b7788ce8-9f08-44ee-9f14-0b21d8791572"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "6/6 [==============================] - 49s 294ms/step - loss: 4.7351 - accuracy: 0.0471 - val_loss: 4.7370 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 4.7285 - accuracy: 0.0706 - val_loss: 4.7391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.7199 - accuracy: 0.0706 - val_loss: 4.7435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 4.7087 - accuracy: 0.0706 - val_loss: 4.7496 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.6817 - accuracy: 0.0706 - val_loss: 4.7734 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.6265 - accuracy: 0.0706 - val_loss: 4.8690 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/150\n",
            "6/6 [==============================] - 1s 145ms/step - loss: 4.5577 - accuracy: 0.0706 - val_loss: 4.9998 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/150\n",
            "6/6 [==============================] - 1s 175ms/step - loss: 4.5043 - accuracy: 0.0706 - val_loss: 5.1499 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/150\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 4.4712 - accuracy: 0.0706 - val_loss: 5.3353 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.4311 - accuracy: 0.0706 - val_loss: 5.4547 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 4.3941 - accuracy: 0.0706 - val_loss: 5.5314 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.3657 - accuracy: 0.0706 - val_loss: 5.6184 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 4.3411 - accuracy: 0.0706 - val_loss: 5.7581 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.3196 - accuracy: 0.0706 - val_loss: 5.9032 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.3031 - accuracy: 0.0706 - val_loss: 5.9640 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 4.2860 - accuracy: 0.0706 - val_loss: 5.9699 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.2708 - accuracy: 0.0706 - val_loss: 6.0821 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.2562 - accuracy: 0.0706 - val_loss: 6.2139 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 4.2448 - accuracy: 0.0706 - val_loss: 6.2609 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 4.2391 - accuracy: 0.0706 - val_loss: 6.3194 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 4.2277 - accuracy: 0.0706 - val_loss: 6.4013 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.2210 - accuracy: 0.0706 - val_loss: 6.4540 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 4.2138 - accuracy: 0.0706 - val_loss: 6.4695 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 4.2056 - accuracy: 0.0706 - val_loss: 6.5738 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 4.1960 - accuracy: 0.0706 - val_loss: 6.6871 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/150\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 4.1886 - accuracy: 0.0706 - val_loss: 6.8101 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/150\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 4.1794 - accuracy: 0.0706 - val_loss: 6.8791 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/150\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 4.1690 - accuracy: 0.0706 - val_loss: 6.7770 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/150\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 4.1591 - accuracy: 0.0706 - val_loss: 6.8066 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 4.1413 - accuracy: 0.0706 - val_loss: 7.0471 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/150\n",
            "6/6 [==============================] - 1s 180ms/step - loss: 4.1240 - accuracy: 0.0706 - val_loss: 6.9821 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 4.1099 - accuracy: 0.0706 - val_loss: 6.9800 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 4.0861 - accuracy: 0.0706 - val_loss: 7.1561 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 4.0591 - accuracy: 0.0706 - val_loss: 7.1947 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 4.0368 - accuracy: 0.0941 - val_loss: 7.4228 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 4.0109 - accuracy: 0.0941 - val_loss: 7.1204 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.9963 - accuracy: 0.0882 - val_loss: 7.2279 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 3.9785 - accuracy: 0.0941 - val_loss: 7.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 3.9471 - accuracy: 0.0824 - val_loss: 7.1362 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 3.9393 - accuracy: 0.0882 - val_loss: 7.6296 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.8942 - accuracy: 0.0941 - val_loss: 7.5241 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/150\n",
            "6/6 [==============================] - 2s 258ms/step - loss: 3.8653 - accuracy: 0.1000 - val_loss: 7.8680 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/150\n",
            "6/6 [==============================] - 1s 176ms/step - loss: 3.8292 - accuracy: 0.0765 - val_loss: 8.1079 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/150\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 3.7943 - accuracy: 0.0941 - val_loss: 8.1133 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/150\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 3.7674 - accuracy: 0.0882 - val_loss: 8.3132 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.7447 - accuracy: 0.0824 - val_loss: 8.2538 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 3.7101 - accuracy: 0.0941 - val_loss: 8.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 3.6821 - accuracy: 0.1000 - val_loss: 8.4264 - val_accuracy: 0.0185\n",
            "Epoch 49/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.6490 - accuracy: 0.1471 - val_loss: 8.6834 - val_accuracy: 0.0741\n",
            "Epoch 50/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 3.6312 - accuracy: 0.1824 - val_loss: 8.6401 - val_accuracy: 0.0926\n",
            "Epoch 51/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.6044 - accuracy: 0.1529 - val_loss: 8.6298 - val_accuracy: 0.0185\n",
            "Epoch 52/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 3.6138 - accuracy: 0.1294 - val_loss: 9.0383 - val_accuracy: 0.0741\n",
            "Epoch 53/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.5507 - accuracy: 0.1353 - val_loss: 8.9261 - val_accuracy: 0.0926\n",
            "Epoch 54/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.5188 - accuracy: 0.1353 - val_loss: 8.9688 - val_accuracy: 0.0926\n",
            "Epoch 55/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 3.4797 - accuracy: 0.1294 - val_loss: 9.0785 - val_accuracy: 0.0926\n",
            "Epoch 56/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 3.4497 - accuracy: 0.1235 - val_loss: 9.2579 - val_accuracy: 0.0926\n",
            "Epoch 57/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 3.4146 - accuracy: 0.1471 - val_loss: 9.3756 - val_accuracy: 0.0741\n",
            "Epoch 58/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.3797 - accuracy: 0.1588 - val_loss: 9.4684 - val_accuracy: 0.0741\n",
            "Epoch 59/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.3414 - accuracy: 0.1706 - val_loss: 9.6655 - val_accuracy: 0.0741\n",
            "Epoch 60/150\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 3.3049 - accuracy: 0.1882 - val_loss: 9.7922 - val_accuracy: 0.0741\n",
            "Epoch 61/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.2679 - accuracy: 0.1706 - val_loss: 9.9759 - val_accuracy: 0.0741\n",
            "Epoch 62/150\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 3.2377 - accuracy: 0.1824 - val_loss: 10.1229 - val_accuracy: 0.0926\n",
            "Epoch 63/150\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 3.2021 - accuracy: 0.1647 - val_loss: 10.0772 - val_accuracy: 0.0741\n",
            "Epoch 64/150\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 3.2033 - accuracy: 0.1706 - val_loss: 9.9038 - val_accuracy: 0.0926\n",
            "Epoch 65/150\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 3.2127 - accuracy: 0.2000 - val_loss: 10.2522 - val_accuracy: 0.0741\n",
            "Epoch 66/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.1459 - accuracy: 0.2059 - val_loss: 10.4480 - val_accuracy: 0.0926\n",
            "Epoch 67/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 3.1007 - accuracy: 0.1765 - val_loss: 10.5470 - val_accuracy: 0.0926\n",
            "Epoch 68/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 3.0567 - accuracy: 0.2353 - val_loss: 10.7137 - val_accuracy: 0.0741\n",
            "Epoch 69/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 3.0238 - accuracy: 0.2588 - val_loss: 10.9228 - val_accuracy: 0.0926\n",
            "Epoch 70/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.9836 - accuracy: 0.2706 - val_loss: 11.0335 - val_accuracy: 0.0926\n",
            "Epoch 71/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.9439 - accuracy: 0.2882 - val_loss: 11.0552 - val_accuracy: 0.0926\n",
            "Epoch 72/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.9111 - accuracy: 0.2765 - val_loss: 11.1970 - val_accuracy: 0.0741\n",
            "Epoch 73/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.8761 - accuracy: 0.2882 - val_loss: 11.3527 - val_accuracy: 0.0926\n",
            "Epoch 74/150\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 2.8385 - accuracy: 0.3059 - val_loss: 11.5390 - val_accuracy: 0.0926\n",
            "Epoch 75/150\n",
            "6/6 [==============================] - 1s 143ms/step - loss: 2.8032 - accuracy: 0.3059 - val_loss: 11.6668 - val_accuracy: 0.0926\n",
            "Epoch 76/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.7710 - accuracy: 0.3000 - val_loss: 11.7970 - val_accuracy: 0.0926\n",
            "Epoch 77/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.7421 - accuracy: 0.2706 - val_loss: 11.9533 - val_accuracy: 0.0926\n",
            "Epoch 78/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.7171 - accuracy: 0.2824 - val_loss: 12.0701 - val_accuracy: 0.0926\n",
            "Epoch 79/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.6976 - accuracy: 0.2824 - val_loss: 12.2974 - val_accuracy: 0.0741\n",
            "Epoch 80/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.6669 - accuracy: 0.3059 - val_loss: 12.3426 - val_accuracy: 0.0926\n",
            "Epoch 81/150\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 2.6337 - accuracy: 0.2941 - val_loss: 12.5052 - val_accuracy: 0.0926\n",
            "Epoch 82/150\n",
            "6/6 [==============================] - 1s 176ms/step - loss: 2.6004 - accuracy: 0.2882 - val_loss: 12.6834 - val_accuracy: 0.0926\n",
            "Epoch 83/150\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 2.5736 - accuracy: 0.2882 - val_loss: 12.8869 - val_accuracy: 0.0926\n",
            "Epoch 84/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.5445 - accuracy: 0.3176 - val_loss: 12.9860 - val_accuracy: 0.0926\n",
            "Epoch 85/150\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 2.5154 - accuracy: 0.3118 - val_loss: 13.0504 - val_accuracy: 0.0926\n",
            "Epoch 86/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.4903 - accuracy: 0.3353 - val_loss: 13.2631 - val_accuracy: 0.0926\n",
            "Epoch 87/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.4944 - accuracy: 0.3059 - val_loss: 13.4110 - val_accuracy: 0.1111\n",
            "Epoch 88/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.5183 - accuracy: 0.3059 - val_loss: 13.0747 - val_accuracy: 0.0926\n",
            "Epoch 89/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.6146 - accuracy: 0.2941 - val_loss: 13.3475 - val_accuracy: 0.0926\n",
            "Epoch 90/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.5103 - accuracy: 0.3294 - val_loss: 13.4120 - val_accuracy: 0.0926\n",
            "Epoch 91/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 2.4849 - accuracy: 0.3235 - val_loss: 13.4857 - val_accuracy: 0.0926\n",
            "Epoch 92/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.4300 - accuracy: 0.3412 - val_loss: 13.6150 - val_accuracy: 0.0926\n",
            "Epoch 93/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.3997 - accuracy: 0.3765 - val_loss: 13.7018 - val_accuracy: 0.0926\n",
            "Epoch 94/150\n",
            "6/6 [==============================] - 1s 91ms/step - loss: 2.3680 - accuracy: 0.3353 - val_loss: 13.8933 - val_accuracy: 0.0926\n",
            "Epoch 95/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.3407 - accuracy: 0.3706 - val_loss: 14.0788 - val_accuracy: 0.0926\n",
            "Epoch 96/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.3114 - accuracy: 0.3882 - val_loss: 14.2133 - val_accuracy: 0.0926\n",
            "Epoch 97/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.2849 - accuracy: 0.3824 - val_loss: 14.4030 - val_accuracy: 0.0926\n",
            "Epoch 98/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.2605 - accuracy: 0.3765 - val_loss: 14.5144 - val_accuracy: 0.0926\n",
            "Epoch 99/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.2376 - accuracy: 0.4000 - val_loss: 14.6081 - val_accuracy: 0.0926\n",
            "Epoch 100/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.2146 - accuracy: 0.4059 - val_loss: 14.7607 - val_accuracy: 0.0926\n",
            "Epoch 101/150\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 2.1984 - accuracy: 0.4118 - val_loss: 14.8466 - val_accuracy: 0.0926\n",
            "Epoch 102/150\n",
            "6/6 [==============================] - 1s 178ms/step - loss: 2.1763 - accuracy: 0.4118 - val_loss: 14.9513 - val_accuracy: 0.0926\n",
            "Epoch 103/150\n",
            "6/6 [==============================] - 1s 173ms/step - loss: 2.1582 - accuracy: 0.4118 - val_loss: 15.0757 - val_accuracy: 0.0926\n",
            "Epoch 104/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 2.1309 - accuracy: 0.3882 - val_loss: 15.1426 - val_accuracy: 0.0926\n",
            "Epoch 105/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 2.1162 - accuracy: 0.3941 - val_loss: 15.3032 - val_accuracy: 0.0926\n",
            "Epoch 106/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.0996 - accuracy: 0.4059 - val_loss: 15.3229 - val_accuracy: 0.0926\n",
            "Epoch 107/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 2.0798 - accuracy: 0.4059 - val_loss: 15.4232 - val_accuracy: 0.0926\n",
            "Epoch 108/150\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 2.0551 - accuracy: 0.4176 - val_loss: 15.5655 - val_accuracy: 0.0926\n",
            "Epoch 109/150\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 2.0374 - accuracy: 0.4059 - val_loss: 15.7517 - val_accuracy: 0.0926\n",
            "Epoch 110/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.0252 - accuracy: 0.4176 - val_loss: 15.8205 - val_accuracy: 0.0926\n",
            "Epoch 111/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.0024 - accuracy: 0.4294 - val_loss: 15.9309 - val_accuracy: 0.0926\n",
            "Epoch 112/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.9881 - accuracy: 0.4235 - val_loss: 16.0389 - val_accuracy: 0.0926\n",
            "Epoch 113/150\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 1.9754 - accuracy: 0.4118 - val_loss: 16.1883 - val_accuracy: 0.0926\n",
            "Epoch 114/150\n",
            "6/6 [==============================] - 2s 309ms/step - loss: 1.9617 - accuracy: 0.3941 - val_loss: 16.0750 - val_accuracy: 0.0926\n",
            "Epoch 115/150\n",
            "6/6 [==============================] - 2s 333ms/step - loss: 1.9431 - accuracy: 0.4059 - val_loss: 16.3071 - val_accuracy: 0.0926\n",
            "Epoch 116/150\n",
            "6/6 [==============================] - 2s 250ms/step - loss: 1.9295 - accuracy: 0.4059 - val_loss: 16.4055 - val_accuracy: 0.0926\n",
            "Epoch 117/150\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 1.9144 - accuracy: 0.4353 - val_loss: 16.4496 - val_accuracy: 0.0926\n",
            "Epoch 118/150\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 1.8924 - accuracy: 0.4176 - val_loss: 16.5489 - val_accuracy: 0.0926\n",
            "Epoch 119/150\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 1.8806 - accuracy: 0.4294 - val_loss: 16.6348 - val_accuracy: 0.0926\n",
            "Epoch 120/150\n",
            "6/6 [==============================] - 1s 112ms/step - loss: 1.8672 - accuracy: 0.4412 - val_loss: 16.6536 - val_accuracy: 0.0926\n",
            "Epoch 121/150\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 1.8533 - accuracy: 0.4294 - val_loss: 16.7685 - val_accuracy: 0.0926\n",
            "Epoch 122/150\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 1.8387 - accuracy: 0.4588 - val_loss: 16.8209 - val_accuracy: 0.0926\n",
            "Epoch 123/150\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 1.8263 - accuracy: 0.4706 - val_loss: 16.9082 - val_accuracy: 0.0926\n",
            "Epoch 124/150\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 1.8115 - accuracy: 0.4765 - val_loss: 16.9326 - val_accuracy: 0.0926\n",
            "Epoch 125/150\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 1.7977 - accuracy: 0.4647 - val_loss: 17.0522 - val_accuracy: 0.0926\n",
            "Epoch 126/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 1.7869 - accuracy: 0.4471 - val_loss: 17.1208 - val_accuracy: 0.0926\n",
            "Epoch 127/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.7653 - accuracy: 0.4471 - val_loss: 17.2455 - val_accuracy: 0.0926\n",
            "Epoch 128/150\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 1.7525 - accuracy: 0.4588 - val_loss: 17.3420 - val_accuracy: 0.0926\n",
            "Epoch 129/150\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 1.7533 - accuracy: 0.4529 - val_loss: 17.3320 - val_accuracy: 0.0926\n",
            "Epoch 130/150\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 1.7414 - accuracy: 0.4765 - val_loss: 17.3821 - val_accuracy: 0.0926\n",
            "Epoch 131/150\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 1.7253 - accuracy: 0.4529 - val_loss: 17.6232 - val_accuracy: 0.0926\n",
            "Epoch 132/150\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 1.7142 - accuracy: 0.4824 - val_loss: 17.5534 - val_accuracy: 0.0926\n",
            "Epoch 133/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.6960 - accuracy: 0.5000 - val_loss: 17.7488 - val_accuracy: 0.0926\n",
            "Epoch 134/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.6967 - accuracy: 0.4647 - val_loss: 17.6727 - val_accuracy: 0.0926\n",
            "Epoch 135/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.6718 - accuracy: 0.4765 - val_loss: 17.8399 - val_accuracy: 0.0926\n",
            "Epoch 136/150\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 1.6646 - accuracy: 0.5118 - val_loss: 17.8364 - val_accuracy: 0.0926\n",
            "Epoch 137/150\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 1.6539 - accuracy: 0.5176 - val_loss: 17.9934 - val_accuracy: 0.0926\n",
            "Epoch 138/150\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 1.6306 - accuracy: 0.5353 - val_loss: 17.9541 - val_accuracy: 0.0926\n",
            "Epoch 139/150\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 1.6187 - accuracy: 0.5353 - val_loss: 18.1163 - val_accuracy: 0.0926\n",
            "Epoch 140/150\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 1.6079 - accuracy: 0.5118 - val_loss: 18.0299 - val_accuracy: 0.0926\n",
            "Epoch 141/150\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 1.6110 - accuracy: 0.5000 - val_loss: 18.1967 - val_accuracy: 0.0926\n",
            "Epoch 142/150\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 1.5921 - accuracy: 0.5059 - val_loss: 18.1115 - val_accuracy: 0.0926\n",
            "Epoch 143/150\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 1.5884 - accuracy: 0.5176 - val_loss: 18.2659 - val_accuracy: 0.0926\n",
            "Epoch 144/150\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 1.5914 - accuracy: 0.5353 - val_loss: 18.4669 - val_accuracy: 0.0926\n",
            "Epoch 145/150\n",
            "6/6 [==============================] - 1s 147ms/step - loss: 1.5679 - accuracy: 0.5353 - val_loss: 18.3018 - val_accuracy: 0.0926\n",
            "Epoch 146/150\n",
            "6/6 [==============================] - 1s 93ms/step - loss: 1.5627 - accuracy: 0.5353 - val_loss: 18.4804 - val_accuracy: 0.0926\n",
            "Epoch 147/150\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 1.5487 - accuracy: 0.5294 - val_loss: 18.5483 - val_accuracy: 0.0926\n",
            "Epoch 148/150\n",
            "6/6 [==============================] - 1s 177ms/step - loss: 1.5289 - accuracy: 0.5176 - val_loss: 18.6383 - val_accuracy: 0.0926\n",
            "Epoch 149/150\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 1.5169 - accuracy: 0.5118 - val_loss: 18.6206 - val_accuracy: 0.0926\n",
            "Epoch 150/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.4966 - accuracy: 0.5412 - val_loss: 18.6959 - val_accuracy: 0.0926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm3 = model3.fit(training_padded, training_labels3, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PISUGvE3zNq9",
        "outputId": "3b539489-1cfd-476b-b5e3-7160284a4caa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "6/6 [==============================] - 6s 277ms/step - loss: 4.7261 - accuracy: 0.0059 - val_loss: 4.7329 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.7181 - accuracy: 0.0294 - val_loss: 4.7377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 4.7093 - accuracy: 0.0235 - val_loss: 4.7482 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.6938 - accuracy: 0.0235 - val_loss: 4.7739 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.6579 - accuracy: 0.0235 - val_loss: 4.8596 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.5961 - accuracy: 0.0353 - val_loss: 5.0639 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.5482 - accuracy: 0.0412 - val_loss: 5.3245 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/150\n",
            "6/6 [==============================] - 1s 147ms/step - loss: 4.4957 - accuracy: 0.0706 - val_loss: 5.4244 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/150\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 4.4556 - accuracy: 0.0706 - val_loss: 5.5016 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/150\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 4.4115 - accuracy: 0.0706 - val_loss: 5.6429 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 4.3729 - accuracy: 0.0706 - val_loss: 5.8059 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.3397 - accuracy: 0.0706 - val_loss: 5.9890 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 4.3130 - accuracy: 0.0706 - val_loss: 6.1495 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.2905 - accuracy: 0.0706 - val_loss: 6.2719 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.2695 - accuracy: 0.0706 - val_loss: 6.3456 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/150\n",
            "6/6 [==============================] - 1s 91ms/step - loss: 4.2529 - accuracy: 0.0706 - val_loss: 6.3791 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 4.2403 - accuracy: 0.0706 - val_loss: 6.4307 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 4.2250 - accuracy: 0.0706 - val_loss: 6.5590 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 4.2150 - accuracy: 0.0706 - val_loss: 6.6536 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.2053 - accuracy: 0.0706 - val_loss: 6.7374 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/150\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 4.1957 - accuracy: 0.0706 - val_loss: 6.7747 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 4.1868 - accuracy: 0.0706 - val_loss: 6.9188 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 4.1769 - accuracy: 0.0706 - val_loss: 7.0163 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.1683 - accuracy: 0.0706 - val_loss: 6.9288 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 4.1506 - accuracy: 0.0706 - val_loss: 7.0412 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 4.1379 - accuracy: 0.0706 - val_loss: 7.0759 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.1196 - accuracy: 0.0706 - val_loss: 7.0507 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/150\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 4.0986 - accuracy: 0.0706 - val_loss: 7.2186 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/150\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 4.0817 - accuracy: 0.0706 - val_loss: 7.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/150\n",
            "6/6 [==============================] - 1s 176ms/step - loss: 4.0518 - accuracy: 0.1000 - val_loss: 7.5270 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/150\n",
            "6/6 [==============================] - 1s 93ms/step - loss: 4.0350 - accuracy: 0.0824 - val_loss: 7.3580 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 4.0104 - accuracy: 0.1000 - val_loss: 7.4863 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.9614 - accuracy: 0.1000 - val_loss: 7.4880 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.9251 - accuracy: 0.1176 - val_loss: 7.7626 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.8900 - accuracy: 0.1176 - val_loss: 8.0344 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.8512 - accuracy: 0.1294 - val_loss: 8.0428 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 3.8245 - accuracy: 0.1353 - val_loss: 8.1009 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.7900 - accuracy: 0.1294 - val_loss: 8.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 3.7918 - accuracy: 0.1353 - val_loss: 7.8964 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 3.8192 - accuracy: 0.1412 - val_loss: 7.6993 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 3.8026 - accuracy: 0.1471 - val_loss: 8.0406 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.7376 - accuracy: 0.1294 - val_loss: 8.4269 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.7026 - accuracy: 0.1353 - val_loss: 8.7550 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.6577 - accuracy: 0.1235 - val_loss: 8.9714 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 3.6166 - accuracy: 0.1353 - val_loss: 9.2464 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 3.5813 - accuracy: 0.1588 - val_loss: 9.3365 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 3.5435 - accuracy: 0.1706 - val_loss: 9.4089 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/150\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 3.5094 - accuracy: 0.1706 - val_loss: 9.6450 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/150\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 3.4775 - accuracy: 0.1529 - val_loss: 9.6640 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/150\n",
            "6/6 [==============================] - 1s 149ms/step - loss: 3.4404 - accuracy: 0.1529 - val_loss: 9.6398 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.4156 - accuracy: 0.1824 - val_loss: 9.9812 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 3.3858 - accuracy: 0.1706 - val_loss: 9.9574 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 3.3526 - accuracy: 0.1765 - val_loss: 10.2222 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.3176 - accuracy: 0.1941 - val_loss: 10.3467 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/150\n",
            "6/6 [==============================] - 1s 91ms/step - loss: 3.3018 - accuracy: 0.2000 - val_loss: 10.4016 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 3.2743 - accuracy: 0.2176 - val_loss: 10.5805 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/150\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 3.2347 - accuracy: 0.2353 - val_loss: 10.8717 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.2057 - accuracy: 0.2706 - val_loss: 11.0127 - val_accuracy: 0.0926\n",
            "Epoch 59/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 3.1737 - accuracy: 0.2824 - val_loss: 11.0922 - val_accuracy: 0.0926\n",
            "Epoch 60/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 3.3126 - accuracy: 0.2176 - val_loss: 10.1205 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/150\n",
            "6/6 [==============================] - 1s 113ms/step - loss: 3.3591 - accuracy: 0.1824 - val_loss: 10.2345 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 3.3082 - accuracy: 0.2059 - val_loss: 10.2836 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 3.2177 - accuracy: 0.2294 - val_loss: 10.6625 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 3.1685 - accuracy: 0.2353 - val_loss: 11.2180 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.1274 - accuracy: 0.2529 - val_loss: 11.5468 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 3.0911 - accuracy: 0.2412 - val_loss: 11.6859 - val_accuracy: 0.0926\n",
            "Epoch 67/150\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 3.0506 - accuracy: 0.2529 - val_loss: 11.8241 - val_accuracy: 0.0926\n",
            "Epoch 68/150\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 3.0193 - accuracy: 0.2529 - val_loss: 12.0590 - val_accuracy: 0.0926\n",
            "Epoch 69/150\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 2.9884 - accuracy: 0.2529 - val_loss: 12.2056 - val_accuracy: 0.0926\n",
            "Epoch 70/150\n",
            "6/6 [==============================] - 1s 114ms/step - loss: 2.9615 - accuracy: 0.2647 - val_loss: 12.3881 - val_accuracy: 0.0926\n",
            "Epoch 71/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.9281 - accuracy: 0.2647 - val_loss: 12.5291 - val_accuracy: 0.0926\n",
            "Epoch 72/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.9005 - accuracy: 0.2765 - val_loss: 12.6629 - val_accuracy: 0.0926\n",
            "Epoch 73/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.8732 - accuracy: 0.3000 - val_loss: 12.8080 - val_accuracy: 0.0926\n",
            "Epoch 74/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.8404 - accuracy: 0.2941 - val_loss: 12.9270 - val_accuracy: 0.0926\n",
            "Epoch 75/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.8025 - accuracy: 0.2882 - val_loss: 13.0756 - val_accuracy: 0.0926\n",
            "Epoch 76/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.7762 - accuracy: 0.2941 - val_loss: 13.3233 - val_accuracy: 0.0926\n",
            "Epoch 77/150\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 2.7452 - accuracy: 0.3118 - val_loss: 13.3939 - val_accuracy: 0.0926\n",
            "Epoch 78/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.7135 - accuracy: 0.3059 - val_loss: 13.5498 - val_accuracy: 0.0926\n",
            "Epoch 79/150\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 2.6887 - accuracy: 0.3118 - val_loss: 13.5756 - val_accuracy: 0.0926\n",
            "Epoch 80/150\n",
            "6/6 [==============================] - 1s 248ms/step - loss: 2.6587 - accuracy: 0.3588 - val_loss: 13.8699 - val_accuracy: 0.0926\n",
            "Epoch 81/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 2.6210 - accuracy: 0.3588 - val_loss: 14.0383 - val_accuracy: 0.0926\n",
            "Epoch 82/150\n",
            "6/6 [==============================] - 2s 292ms/step - loss: 2.5871 - accuracy: 0.3235 - val_loss: 14.1171 - val_accuracy: 0.0926\n",
            "Epoch 83/150\n",
            "6/6 [==============================] - 2s 388ms/step - loss: 2.5642 - accuracy: 0.3412 - val_loss: 14.3982 - val_accuracy: 0.0926\n",
            "Epoch 84/150\n",
            "6/6 [==============================] - 1s 179ms/step - loss: 2.5842 - accuracy: 0.3294 - val_loss: 13.9059 - val_accuracy: 0.0926\n",
            "Epoch 85/150\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 2.6497 - accuracy: 0.3176 - val_loss: 13.8802 - val_accuracy: 0.0926\n",
            "Epoch 86/150\n",
            "6/6 [==============================] - 1s 220ms/step - loss: 2.5823 - accuracy: 0.3235 - val_loss: 14.0920 - val_accuracy: 0.0926\n",
            "Epoch 87/150\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 2.5494 - accuracy: 0.3294 - val_loss: 14.4668 - val_accuracy: 0.0926\n",
            "Epoch 88/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.5094 - accuracy: 0.3588 - val_loss: 14.6383 - val_accuracy: 0.0926\n",
            "Epoch 89/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.4660 - accuracy: 0.3941 - val_loss: 14.8176 - val_accuracy: 0.0926\n",
            "Epoch 90/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.4242 - accuracy: 0.3824 - val_loss: 14.7605 - val_accuracy: 0.0926\n",
            "Epoch 91/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.4050 - accuracy: 0.3706 - val_loss: 14.8320 - val_accuracy: 0.0926\n",
            "Epoch 92/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.3738 - accuracy: 0.3882 - val_loss: 15.1195 - val_accuracy: 0.0926\n",
            "Epoch 93/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 2.3436 - accuracy: 0.4000 - val_loss: 15.2700 - val_accuracy: 0.0926\n",
            "Epoch 94/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 2.3111 - accuracy: 0.4176 - val_loss: 15.3510 - val_accuracy: 0.0926\n",
            "Epoch 95/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 2.2830 - accuracy: 0.4235 - val_loss: 15.6147 - val_accuracy: 0.0926\n",
            "Epoch 96/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.2522 - accuracy: 0.4235 - val_loss: 15.7725 - val_accuracy: 0.0926\n",
            "Epoch 97/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.2273 - accuracy: 0.4176 - val_loss: 16.0171 - val_accuracy: 0.0926\n",
            "Epoch 98/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.2033 - accuracy: 0.4176 - val_loss: 16.0413 - val_accuracy: 0.0926\n",
            "Epoch 99/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 2.1846 - accuracy: 0.4118 - val_loss: 16.2576 - val_accuracy: 0.0926\n",
            "Epoch 100/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 2.1651 - accuracy: 0.4294 - val_loss: 16.3624 - val_accuracy: 0.0926\n",
            "Epoch 101/150\n",
            "6/6 [==============================] - 1s 114ms/step - loss: 2.1425 - accuracy: 0.4353 - val_loss: 16.5824 - val_accuracy: 0.0926\n",
            "Epoch 102/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 2.1140 - accuracy: 0.4294 - val_loss: 16.6173 - val_accuracy: 0.0926\n",
            "Epoch 103/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.0935 - accuracy: 0.4471 - val_loss: 16.8007 - val_accuracy: 0.0926\n",
            "Epoch 104/150\n",
            "6/6 [==============================] - 1s 165ms/step - loss: 2.0685 - accuracy: 0.4471 - val_loss: 16.9329 - val_accuracy: 0.0926\n",
            "Epoch 105/150\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 2.0498 - accuracy: 0.4529 - val_loss: 16.8849 - val_accuracy: 0.0926\n",
            "Epoch 106/150\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 2.0299 - accuracy: 0.4588 - val_loss: 17.0054 - val_accuracy: 0.0926\n",
            "Epoch 107/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 2.0125 - accuracy: 0.4529 - val_loss: 17.2210 - val_accuracy: 0.0926\n",
            "Epoch 108/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.9971 - accuracy: 0.4529 - val_loss: 17.3386 - val_accuracy: 0.0926\n",
            "Epoch 109/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.9741 - accuracy: 0.4412 - val_loss: 17.4922 - val_accuracy: 0.0926\n",
            "Epoch 110/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.9581 - accuracy: 0.4529 - val_loss: 17.5525 - val_accuracy: 0.0926\n",
            "Epoch 111/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.9510 - accuracy: 0.4412 - val_loss: 17.6730 - val_accuracy: 0.0926\n",
            "Epoch 112/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.9676 - accuracy: 0.4471 - val_loss: 17.6742 - val_accuracy: 0.0926\n",
            "Epoch 113/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.9339 - accuracy: 0.4588 - val_loss: 17.7026 - val_accuracy: 0.0926\n",
            "Epoch 114/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.9111 - accuracy: 0.4529 - val_loss: 17.8763 - val_accuracy: 0.0926\n",
            "Epoch 115/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.8856 - accuracy: 0.4529 - val_loss: 17.9931 - val_accuracy: 0.0741\n",
            "Epoch 116/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.8676 - accuracy: 0.4647 - val_loss: 18.1389 - val_accuracy: 0.0741\n",
            "Epoch 117/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.8590 - accuracy: 0.4529 - val_loss: 18.2924 - val_accuracy: 0.0926\n",
            "Epoch 118/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.8392 - accuracy: 0.4588 - val_loss: 18.4145 - val_accuracy: 0.0926\n",
            "Epoch 119/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 1.8258 - accuracy: 0.4588 - val_loss: 18.5563 - val_accuracy: 0.0741\n",
            "Epoch 120/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.8108 - accuracy: 0.4706 - val_loss: 18.6420 - val_accuracy: 0.0926\n",
            "Epoch 121/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.7970 - accuracy: 0.4471 - val_loss: 18.8273 - val_accuracy: 0.0741\n",
            "Epoch 122/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.7787 - accuracy: 0.4588 - val_loss: 18.8777 - val_accuracy: 0.0741\n",
            "Epoch 123/150\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 1.7743 - accuracy: 0.4765 - val_loss: 18.9799 - val_accuracy: 0.0741\n",
            "Epoch 124/150\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 1.7460 - accuracy: 0.4647 - val_loss: 19.0298 - val_accuracy: 0.0741\n",
            "Epoch 125/150\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 1.7302 - accuracy: 0.4824 - val_loss: 19.0850 - val_accuracy: 0.0741\n",
            "Epoch 126/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.7163 - accuracy: 0.4706 - val_loss: 19.2992 - val_accuracy: 0.0741\n",
            "Epoch 127/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.7024 - accuracy: 0.4765 - val_loss: 19.4398 - val_accuracy: 0.0741\n",
            "Epoch 128/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.6945 - accuracy: 0.4588 - val_loss: 19.5121 - val_accuracy: 0.0741\n",
            "Epoch 129/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 1.6747 - accuracy: 0.4824 - val_loss: 19.4673 - val_accuracy: 0.0741\n",
            "Epoch 130/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.6778 - accuracy: 0.4882 - val_loss: 19.5771 - val_accuracy: 0.0741\n",
            "Epoch 131/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.6507 - accuracy: 0.4941 - val_loss: 19.7376 - val_accuracy: 0.0741\n",
            "Epoch 132/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.6512 - accuracy: 0.4882 - val_loss: 19.8731 - val_accuracy: 0.0741\n",
            "Epoch 133/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.6358 - accuracy: 0.4941 - val_loss: 20.0083 - val_accuracy: 0.0741\n",
            "Epoch 134/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 1.6321 - accuracy: 0.4882 - val_loss: 19.9721 - val_accuracy: 0.0741\n",
            "Epoch 135/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.6085 - accuracy: 0.5118 - val_loss: 20.0206 - val_accuracy: 0.0741\n",
            "Epoch 136/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.6063 - accuracy: 0.5000 - val_loss: 20.1150 - val_accuracy: 0.0741\n",
            "Epoch 137/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 1.5991 - accuracy: 0.4882 - val_loss: 20.2647 - val_accuracy: 0.0741\n",
            "Epoch 138/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.5808 - accuracy: 0.5176 - val_loss: 20.3122 - val_accuracy: 0.0741\n",
            "Epoch 139/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.5672 - accuracy: 0.5000 - val_loss: 20.4591 - val_accuracy: 0.0741\n",
            "Epoch 140/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.5598 - accuracy: 0.5000 - val_loss: 20.5444 - val_accuracy: 0.0741\n",
            "Epoch 141/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.5472 - accuracy: 0.4824 - val_loss: 20.6619 - val_accuracy: 0.0741\n",
            "Epoch 142/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 1.5439 - accuracy: 0.4941 - val_loss: 20.8043 - val_accuracy: 0.0741\n",
            "Epoch 143/150\n",
            "6/6 [==============================] - 1s 163ms/step - loss: 1.5263 - accuracy: 0.5059 - val_loss: 20.9237 - val_accuracy: 0.0741\n",
            "Epoch 144/150\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 1.5209 - accuracy: 0.5176 - val_loss: 20.9691 - val_accuracy: 0.0741\n",
            "Epoch 145/150\n",
            "6/6 [==============================] - 1s 180ms/step - loss: 1.5165 - accuracy: 0.5294 - val_loss: 21.1101 - val_accuracy: 0.0741\n",
            "Epoch 146/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.5195 - accuracy: 0.5118 - val_loss: 20.9771 - val_accuracy: 0.0741\n",
            "Epoch 147/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.5080 - accuracy: 0.5235 - val_loss: 21.3172 - val_accuracy: 0.0741\n",
            "Epoch 148/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.4894 - accuracy: 0.5294 - val_loss: 21.2400 - val_accuracy: 0.0741\n",
            "Epoch 149/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.4851 - accuracy: 0.5118 - val_loss: 21.3545 - val_accuracy: 0.0741\n",
            "Epoch 150/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.5047 - accuracy: 0.5118 - val_loss: 21.4734 - val_accuracy: 0.0741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm4 = model4.fit(training_padded, training_labels4, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHlIkA7WzPLr",
        "outputId": "212219c2-4707-4535-e732-9bdfbb461a14"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "6/6 [==============================] - 4s 287ms/step - loss: 4.7596 - accuracy: 0.0059 - val_loss: 4.7704 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 4.7492 - accuracy: 0.0235 - val_loss: 4.7821 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 4.7341 - accuracy: 0.0235 - val_loss: 4.8024 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.7062 - accuracy: 0.0765 - val_loss: 4.8571 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.6442 - accuracy: 0.0706 - val_loss: 5.0843 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.5163 - accuracy: 0.0706 - val_loss: 5.4840 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 4.4659 - accuracy: 0.0706 - val_loss: 5.7794 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.4313 - accuracy: 0.0706 - val_loss: 5.8981 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/150\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 4.3972 - accuracy: 0.0706 - val_loss: 6.0158 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.3695 - accuracy: 0.0706 - val_loss: 6.0912 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/150\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 4.3429 - accuracy: 0.0706 - val_loss: 6.1743 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/150\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 4.3252 - accuracy: 0.0706 - val_loss: 6.1943 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/150\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 4.3090 - accuracy: 0.0706 - val_loss: 6.2638 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.2965 - accuracy: 0.0706 - val_loss: 6.4212 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 4.2857 - accuracy: 0.0706 - val_loss: 6.5993 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.2785 - accuracy: 0.0706 - val_loss: 6.7762 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 4.2711 - accuracy: 0.0706 - val_loss: 6.8412 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 4.2620 - accuracy: 0.0706 - val_loss: 6.8531 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 4.2574 - accuracy: 0.0706 - val_loss: 6.7828 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 4.2526 - accuracy: 0.0706 - val_loss: 6.8565 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 4.2490 - accuracy: 0.0706 - val_loss: 6.9583 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 4.2442 - accuracy: 0.0706 - val_loss: 7.0696 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/150\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 4.2413 - accuracy: 0.0706 - val_loss: 7.1217 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 4.2387 - accuracy: 0.0706 - val_loss: 7.2476 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.2359 - accuracy: 0.0706 - val_loss: 7.1956 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 4.2288 - accuracy: 0.0706 - val_loss: 7.2129 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 4.2252 - accuracy: 0.0706 - val_loss: 7.2132 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.2199 - accuracy: 0.0706 - val_loss: 7.1992 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 4.2145 - accuracy: 0.0706 - val_loss: 7.4417 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/150\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 4.2102 - accuracy: 0.0706 - val_loss: 7.5470 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/150\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 4.2050 - accuracy: 0.0706 - val_loss: 7.3717 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/150\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 4.1987 - accuracy: 0.0706 - val_loss: 7.4321 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/150\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 4.1934 - accuracy: 0.0706 - val_loss: 7.6220 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/150\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 4.1788 - accuracy: 0.0706 - val_loss: 7.5266 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/150\n",
            "6/6 [==============================] - 1s 158ms/step - loss: 4.1718 - accuracy: 0.0706 - val_loss: 7.6264 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 4.1585 - accuracy: 0.0706 - val_loss: 7.6331 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.1372 - accuracy: 0.0706 - val_loss: 8.1065 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 4.1397 - accuracy: 0.0706 - val_loss: 7.4699 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.1306 - accuracy: 0.0706 - val_loss: 7.5053 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.1109 - accuracy: 0.0706 - val_loss: 7.8219 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 4.0884 - accuracy: 0.0706 - val_loss: 8.0767 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 4.0701 - accuracy: 0.0706 - val_loss: 8.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 4.0468 - accuracy: 0.0706 - val_loss: 8.0216 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 4.0278 - accuracy: 0.0706 - val_loss: 8.3005 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 4.0043 - accuracy: 0.0706 - val_loss: 8.5424 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 3.9809 - accuracy: 0.0765 - val_loss: 8.4196 - val_accuracy: 0.0926\n",
            "Epoch 47/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 3.9530 - accuracy: 0.0941 - val_loss: 8.7712 - val_accuracy: 0.0926\n",
            "Epoch 48/150\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 3.9187 - accuracy: 0.0941 - val_loss: 8.5786 - val_accuracy: 0.0926\n",
            "Epoch 49/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 3.8929 - accuracy: 0.1000 - val_loss: 8.7926 - val_accuracy: 0.0926\n",
            "Epoch 50/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 3.8587 - accuracy: 0.1000 - val_loss: 8.9468 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 3.8240 - accuracy: 0.1176 - val_loss: 9.6691 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/150\n",
            "6/6 [==============================] - 1s 114ms/step - loss: 3.8171 - accuracy: 0.1000 - val_loss: 8.9947 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/150\n",
            "6/6 [==============================] - 1s 181ms/step - loss: 3.7578 - accuracy: 0.1176 - val_loss: 8.9110 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/150\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 3.7265 - accuracy: 0.1706 - val_loss: 9.5458 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/150\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 3.6819 - accuracy: 0.1765 - val_loss: 9.4316 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.6398 - accuracy: 0.1647 - val_loss: 9.7958 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 3.5941 - accuracy: 0.1529 - val_loss: 9.8482 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 3.5576 - accuracy: 0.1765 - val_loss: 10.3059 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 3.5253 - accuracy: 0.1412 - val_loss: 10.0792 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.4820 - accuracy: 0.1882 - val_loss: 10.4493 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 3.4375 - accuracy: 0.1824 - val_loss: 10.6113 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.3933 - accuracy: 0.2176 - val_loss: 10.6164 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.3516 - accuracy: 0.2059 - val_loss: 10.9923 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.3162 - accuracy: 0.2118 - val_loss: 10.7961 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.3071 - accuracy: 0.2412 - val_loss: 11.1971 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.2639 - accuracy: 0.2000 - val_loss: 11.2412 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 3.2215 - accuracy: 0.2529 - val_loss: 11.1662 - val_accuracy: 0.0741\n",
            "Epoch 68/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 3.1717 - accuracy: 0.2647 - val_loss: 11.6208 - val_accuracy: 0.0741\n",
            "Epoch 69/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 3.1315 - accuracy: 0.2765 - val_loss: 11.7427 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.0959 - accuracy: 0.2471 - val_loss: 11.9829 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 3.0539 - accuracy: 0.2647 - val_loss: 11.9341 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/150\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 3.0173 - accuracy: 0.2706 - val_loss: 12.1686 - val_accuracy: 0.0741\n",
            "Epoch 73/150\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 2.9784 - accuracy: 0.2706 - val_loss: 12.2618 - val_accuracy: 0.0741\n",
            "Epoch 74/150\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 2.9339 - accuracy: 0.3000 - val_loss: 11.7932 - val_accuracy: 0.0741\n",
            "Epoch 75/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.9439 - accuracy: 0.2941 - val_loss: 12.3889 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 2.9485 - accuracy: 0.2353 - val_loss: 12.3912 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.9191 - accuracy: 0.2882 - val_loss: 12.3222 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.8791 - accuracy: 0.2765 - val_loss: 12.7127 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.8118 - accuracy: 0.3118 - val_loss: 13.0955 - val_accuracy: 0.0741\n",
            "Epoch 80/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 2.7625 - accuracy: 0.2765 - val_loss: 13.2317 - val_accuracy: 0.0741\n",
            "Epoch 81/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.7233 - accuracy: 0.2706 - val_loss: 13.2109 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.6743 - accuracy: 0.3353 - val_loss: 13.4463 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 2.6413 - accuracy: 0.3529 - val_loss: 13.4149 - val_accuracy: 0.0741\n",
            "Epoch 84/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 2.6012 - accuracy: 0.3706 - val_loss: 13.6671 - val_accuracy: 0.0741\n",
            "Epoch 85/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.5683 - accuracy: 0.3824 - val_loss: 13.7744 - val_accuracy: 0.0741\n",
            "Epoch 86/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.5290 - accuracy: 0.3706 - val_loss: 13.9643 - val_accuracy: 0.0741\n",
            "Epoch 87/150\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 2.5024 - accuracy: 0.3824 - val_loss: 14.0870 - val_accuracy: 0.0741\n",
            "Epoch 88/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 2.4644 - accuracy: 0.4059 - val_loss: 14.2781 - val_accuracy: 0.0741\n",
            "Epoch 89/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.4364 - accuracy: 0.3882 - val_loss: 14.4357 - val_accuracy: 0.0741\n",
            "Epoch 90/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.3986 - accuracy: 0.4118 - val_loss: 14.4884 - val_accuracy: 0.0741\n",
            "Epoch 91/150\n",
            "6/6 [==============================] - 1s 143ms/step - loss: 2.3704 - accuracy: 0.4235 - val_loss: 14.7132 - val_accuracy: 0.0741\n",
            "Epoch 92/150\n",
            "6/6 [==============================] - 1s 175ms/step - loss: 2.3424 - accuracy: 0.4059 - val_loss: 14.8589 - val_accuracy: 0.0741\n",
            "Epoch 93/150\n",
            "6/6 [==============================] - 1s 173ms/step - loss: 2.3093 - accuracy: 0.4235 - val_loss: 14.9999 - val_accuracy: 0.0741\n",
            "Epoch 94/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.2835 - accuracy: 0.4118 - val_loss: 14.9541 - val_accuracy: 0.0741\n",
            "Epoch 95/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.2692 - accuracy: 0.4353 - val_loss: 15.1165 - val_accuracy: 0.0741\n",
            "Epoch 96/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 2.2314 - accuracy: 0.4353 - val_loss: 15.3133 - val_accuracy: 0.0741\n",
            "Epoch 97/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.2013 - accuracy: 0.4353 - val_loss: 15.4306 - val_accuracy: 0.0741\n",
            "Epoch 98/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.1817 - accuracy: 0.4294 - val_loss: 15.5031 - val_accuracy: 0.0741\n",
            "Epoch 99/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.1487 - accuracy: 0.4353 - val_loss: 15.6901 - val_accuracy: 0.0741\n",
            "Epoch 100/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.1261 - accuracy: 0.4353 - val_loss: 15.6099 - val_accuracy: 0.0741\n",
            "Epoch 101/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.1006 - accuracy: 0.4353 - val_loss: 15.9063 - val_accuracy: 0.0741\n",
            "Epoch 102/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 2.0879 - accuracy: 0.4235 - val_loss: 15.9532 - val_accuracy: 0.0741\n",
            "Epoch 103/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.0590 - accuracy: 0.4294 - val_loss: 16.0767 - val_accuracy: 0.0741\n",
            "Epoch 104/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 2.0873 - accuracy: 0.4176 - val_loss: 16.0054 - val_accuracy: 0.0741\n",
            "Epoch 105/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.0543 - accuracy: 0.4353 - val_loss: 16.3914 - val_accuracy: 0.0741\n",
            "Epoch 106/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.0084 - accuracy: 0.4588 - val_loss: 16.3019 - val_accuracy: 0.0741\n",
            "Epoch 107/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.9810 - accuracy: 0.4471 - val_loss: 16.5430 - val_accuracy: 0.0741\n",
            "Epoch 108/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 1.9591 - accuracy: 0.4529 - val_loss: 16.6597 - val_accuracy: 0.0741\n",
            "Epoch 109/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.9321 - accuracy: 0.4529 - val_loss: 16.6696 - val_accuracy: 0.0741\n",
            "Epoch 110/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.9172 - accuracy: 0.4529 - val_loss: 16.9709 - val_accuracy: 0.0741\n",
            "Epoch 111/150\n",
            "6/6 [==============================] - 1s 176ms/step - loss: 1.8940 - accuracy: 0.4529 - val_loss: 16.9363 - val_accuracy: 0.0741\n",
            "Epoch 112/150\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 1.8754 - accuracy: 0.4706 - val_loss: 17.0875 - val_accuracy: 0.0741\n",
            "Epoch 113/150\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 1.8591 - accuracy: 0.4706 - val_loss: 17.3158 - val_accuracy: 0.0741\n",
            "Epoch 114/150\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 1.8341 - accuracy: 0.4588 - val_loss: 17.2526 - val_accuracy: 0.0741\n",
            "Epoch 115/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.8193 - accuracy: 0.4882 - val_loss: 17.3265 - val_accuracy: 0.0741\n",
            "Epoch 116/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.7964 - accuracy: 0.4765 - val_loss: 17.4597 - val_accuracy: 0.0741\n",
            "Epoch 117/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.7807 - accuracy: 0.4824 - val_loss: 17.5979 - val_accuracy: 0.0741\n",
            "Epoch 118/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 1.7630 - accuracy: 0.5000 - val_loss: 17.6350 - val_accuracy: 0.0741\n",
            "Epoch 119/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.7555 - accuracy: 0.4882 - val_loss: 17.7375 - val_accuracy: 0.0741\n",
            "Epoch 120/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 1.7390 - accuracy: 0.4765 - val_loss: 17.8383 - val_accuracy: 0.0741\n",
            "Epoch 121/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.7182 - accuracy: 0.4706 - val_loss: 17.8783 - val_accuracy: 0.0741\n",
            "Epoch 122/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.7123 - accuracy: 0.5000 - val_loss: 18.0336 - val_accuracy: 0.0741\n",
            "Epoch 123/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.6993 - accuracy: 0.4706 - val_loss: 18.1210 - val_accuracy: 0.0741\n",
            "Epoch 124/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.6768 - accuracy: 0.5059 - val_loss: 18.1368 - val_accuracy: 0.0741\n",
            "Epoch 125/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.6662 - accuracy: 0.5118 - val_loss: 18.2111 - val_accuracy: 0.0741\n",
            "Epoch 126/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.6472 - accuracy: 0.4941 - val_loss: 18.3651 - val_accuracy: 0.0741\n",
            "Epoch 127/150\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 1.6292 - accuracy: 0.5176 - val_loss: 18.4095 - val_accuracy: 0.0741\n",
            "Epoch 128/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.6208 - accuracy: 0.5176 - val_loss: 18.4584 - val_accuracy: 0.0741\n",
            "Epoch 129/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.6168 - accuracy: 0.4824 - val_loss: 18.6879 - val_accuracy: 0.0741\n",
            "Epoch 130/150\n",
            "6/6 [==============================] - 1s 165ms/step - loss: 1.5918 - accuracy: 0.4941 - val_loss: 18.6358 - val_accuracy: 0.0741\n",
            "Epoch 131/150\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 1.5833 - accuracy: 0.5000 - val_loss: 18.7746 - val_accuracy: 0.0741\n",
            "Epoch 132/150\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 1.5733 - accuracy: 0.4706 - val_loss: 18.9423 - val_accuracy: 0.0741\n",
            "Epoch 133/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 1.5556 - accuracy: 0.5235 - val_loss: 19.0080 - val_accuracy: 0.0741\n",
            "Epoch 134/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.5432 - accuracy: 0.5235 - val_loss: 19.0579 - val_accuracy: 0.0741\n",
            "Epoch 135/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.5348 - accuracy: 0.5176 - val_loss: 19.1293 - val_accuracy: 0.0741\n",
            "Epoch 136/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.5342 - accuracy: 0.5118 - val_loss: 18.8538 - val_accuracy: 0.0741\n",
            "Epoch 137/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 2.6338 - accuracy: 0.3000 - val_loss: 15.9946 - val_accuracy: 0.0741\n",
            "Epoch 138/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.4325 - accuracy: 0.2647 - val_loss: 16.1549 - val_accuracy: 0.0741\n",
            "Epoch 139/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.2616 - accuracy: 0.3706 - val_loss: 16.3461 - val_accuracy: 0.0741\n",
            "Epoch 140/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.1444 - accuracy: 0.3765 - val_loss: 16.5287 - val_accuracy: 0.0741\n",
            "Epoch 141/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 2.0489 - accuracy: 0.4353 - val_loss: 16.6917 - val_accuracy: 0.0741\n",
            "Epoch 142/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.9399 - accuracy: 0.4647 - val_loss: 16.8929 - val_accuracy: 0.0741\n",
            "Epoch 143/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 1.8857 - accuracy: 0.4353 - val_loss: 16.9415 - val_accuracy: 0.0741\n",
            "Epoch 144/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.8265 - accuracy: 0.4647 - val_loss: 16.9710 - val_accuracy: 0.0741\n",
            "Epoch 145/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.7842 - accuracy: 0.4824 - val_loss: 17.1112 - val_accuracy: 0.0741\n",
            "Epoch 146/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.7492 - accuracy: 0.4941 - val_loss: 17.3436 - val_accuracy: 0.0741\n",
            "Epoch 147/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.7199 - accuracy: 0.5000 - val_loss: 17.4529 - val_accuracy: 0.0741\n",
            "Epoch 148/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.6853 - accuracy: 0.5000 - val_loss: 17.6598 - val_accuracy: 0.0741\n",
            "Epoch 149/150\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 1.6584 - accuracy: 0.5000 - val_loss: 17.8611 - val_accuracy: 0.0741\n",
            "Epoch 150/150\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 1.6396 - accuracy: 0.5059 - val_loss: 18.0458 - val_accuracy: 0.0741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm5 = model5.fit(training_padded, training_labels5, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY074MI1zQri",
        "outputId": "406fcf02-68be-4c94-9899-08827b27d50f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "6/6 [==============================] - 9s 298ms/step - loss: 4.7443 - accuracy: 0.0235 - val_loss: 4.7459 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 4.7377 - accuracy: 0.0471 - val_loss: 4.7517 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 4.7307 - accuracy: 0.0471 - val_loss: 4.7578 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 4.7206 - accuracy: 0.0471 - val_loss: 4.7694 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 4.7037 - accuracy: 0.0471 - val_loss: 4.7975 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.6620 - accuracy: 0.0471 - val_loss: 4.9290 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/150\n",
            "6/6 [==============================] - 1s 93ms/step - loss: 4.5963 - accuracy: 0.0471 - val_loss: 5.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 4.5292 - accuracy: 0.0765 - val_loss: 5.2752 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/150\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 4.4829 - accuracy: 0.0706 - val_loss: 5.4353 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/150\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 4.4358 - accuracy: 0.0706 - val_loss: 5.5751 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/150\n",
            "6/6 [==============================] - 1s 143ms/step - loss: 4.3955 - accuracy: 0.0706 - val_loss: 5.6570 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 4.3599 - accuracy: 0.0706 - val_loss: 5.7857 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.3328 - accuracy: 0.0706 - val_loss: 5.9359 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.3068 - accuracy: 0.0706 - val_loss: 6.1152 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 4.2814 - accuracy: 0.0706 - val_loss: 6.2416 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.2624 - accuracy: 0.0706 - val_loss: 6.4413 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.2488 - accuracy: 0.0706 - val_loss: 6.5841 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/150\n",
            "6/6 [==============================] - 1s 93ms/step - loss: 4.2371 - accuracy: 0.0706 - val_loss: 6.6778 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 4.2220 - accuracy: 0.0706 - val_loss: 6.6691 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 4.2122 - accuracy: 0.0706 - val_loss: 6.7788 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 4.2004 - accuracy: 0.0706 - val_loss: 6.6694 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.1899 - accuracy: 0.0706 - val_loss: 6.7670 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 4.1779 - accuracy: 0.0706 - val_loss: 6.9262 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/150\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 4.1651 - accuracy: 0.0706 - val_loss: 6.9477 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 4.1553 - accuracy: 0.0706 - val_loss: 7.0294 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.1417 - accuracy: 0.0706 - val_loss: 7.1195 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 4.1252 - accuracy: 0.0941 - val_loss: 7.1105 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/150\n",
            "6/6 [==============================] - 1s 163ms/step - loss: 4.1081 - accuracy: 0.0941 - val_loss: 7.1763 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/150\n",
            "6/6 [==============================] - 1s 181ms/step - loss: 4.1046 - accuracy: 0.1118 - val_loss: 7.2818 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/150\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 4.0776 - accuracy: 0.1118 - val_loss: 7.2391 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 4.0539 - accuracy: 0.1118 - val_loss: 7.1889 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 4.0328 - accuracy: 0.1118 - val_loss: 7.3341 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/150\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 4.0093 - accuracy: 0.1118 - val_loss: 7.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 3.9822 - accuracy: 0.1118 - val_loss: 7.5644 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.9568 - accuracy: 0.1118 - val_loss: 7.6888 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 3.9424 - accuracy: 0.1353 - val_loss: 7.5472 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 3.9306 - accuracy: 0.1118 - val_loss: 7.6009 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 3.8960 - accuracy: 0.1235 - val_loss: 7.6522 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 3.8776 - accuracy: 0.1412 - val_loss: 7.7998 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 3.8480 - accuracy: 0.1353 - val_loss: 7.8795 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/150\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 3.8223 - accuracy: 0.1412 - val_loss: 7.9289 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 3.7990 - accuracy: 0.1353 - val_loss: 7.9410 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 3.7826 - accuracy: 0.1353 - val_loss: 8.0490 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.7590 - accuracy: 0.1471 - val_loss: 8.0738 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 3.7279 - accuracy: 0.1412 - val_loss: 8.2190 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 3.7026 - accuracy: 0.1412 - val_loss: 8.2737 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/150\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 3.6737 - accuracy: 0.1588 - val_loss: 8.4414 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/150\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 3.6437 - accuracy: 0.1588 - val_loss: 8.4732 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/150\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 3.6507 - accuracy: 0.1706 - val_loss: 8.5613 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 3.6017 - accuracy: 0.1824 - val_loss: 8.6479 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 3.5821 - accuracy: 0.1824 - val_loss: 8.6439 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 3.5545 - accuracy: 0.1882 - val_loss: 8.8111 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 3.5316 - accuracy: 0.1647 - val_loss: 8.9891 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/150\n",
            "6/6 [==============================] - 1s 93ms/step - loss: 3.4968 - accuracy: 0.1824 - val_loss: 9.0655 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.4724 - accuracy: 0.1824 - val_loss: 9.0565 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 3.4402 - accuracy: 0.2118 - val_loss: 9.1314 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 3.4093 - accuracy: 0.2176 - val_loss: 9.2780 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 3.4253 - accuracy: 0.1941 - val_loss: 9.1784 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 3.3770 - accuracy: 0.2412 - val_loss: 9.4293 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 3.3323 - accuracy: 0.2471 - val_loss: 9.4179 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 3.2965 - accuracy: 0.2294 - val_loss: 9.5349 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 3.2612 - accuracy: 0.2529 - val_loss: 9.5997 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 3.2302 - accuracy: 0.2529 - val_loss: 9.8108 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 3.1916 - accuracy: 0.2529 - val_loss: 9.9190 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 3.1653 - accuracy: 0.2765 - val_loss: 10.1007 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/150\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 3.1271 - accuracy: 0.2824 - val_loss: 10.3143 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/150\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 3.0923 - accuracy: 0.2824 - val_loss: 10.5107 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/150\n",
            "6/6 [==============================] - 1s 175ms/step - loss: 3.0720 - accuracy: 0.2882 - val_loss: 10.6112 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 3.0363 - accuracy: 0.2824 - val_loss: 10.7065 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 3.0036 - accuracy: 0.3000 - val_loss: 10.7887 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 2.9684 - accuracy: 0.3000 - val_loss: 10.9100 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.9403 - accuracy: 0.2941 - val_loss: 11.1403 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 2.9133 - accuracy: 0.3000 - val_loss: 11.2007 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.8794 - accuracy: 0.3059 - val_loss: 11.4446 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 2.8504 - accuracy: 0.3000 - val_loss: 11.5874 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.8250 - accuracy: 0.3000 - val_loss: 11.7316 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.7903 - accuracy: 0.3235 - val_loss: 11.8745 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.7593 - accuracy: 0.3353 - val_loss: 12.0247 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.7308 - accuracy: 0.3353 - val_loss: 12.1778 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 2.7043 - accuracy: 0.3176 - val_loss: 12.3351 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/150\n",
            "6/6 [==============================] - 1s 114ms/step - loss: 2.6785 - accuracy: 0.3412 - val_loss: 12.4297 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/150\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 2.6527 - accuracy: 0.3353 - val_loss: 12.4844 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.6454 - accuracy: 0.3118 - val_loss: 12.6512 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 2.6047 - accuracy: 0.3529 - val_loss: 12.8038 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/150\n",
            "6/6 [==============================] - 1s 173ms/step - loss: 2.5836 - accuracy: 0.3412 - val_loss: 12.9467 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/150\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 2.5531 - accuracy: 0.3471 - val_loss: 13.0750 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/150\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 2.5281 - accuracy: 0.3882 - val_loss: 13.2216 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 2.5009 - accuracy: 0.3824 - val_loss: 13.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.4856 - accuracy: 0.3706 - val_loss: 13.5905 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.4500 - accuracy: 0.3882 - val_loss: 13.7403 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 2.4282 - accuracy: 0.3706 - val_loss: 13.7499 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/150\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.4094 - accuracy: 0.3882 - val_loss: 13.9632 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 2.3875 - accuracy: 0.3824 - val_loss: 14.0900 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/150\n",
            "6/6 [==============================] - 1s 94ms/step - loss: 2.3546 - accuracy: 0.4059 - val_loss: 14.2560 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.3350 - accuracy: 0.3647 - val_loss: 14.4215 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 2.3218 - accuracy: 0.3882 - val_loss: 14.6037 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/150\n",
            "6/6 [==============================] - 1s 113ms/step - loss: 2.3855 - accuracy: 0.3176 - val_loss: 14.6247 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 2.3146 - accuracy: 0.4118 - val_loss: 14.3583 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 2.3209 - accuracy: 0.3941 - val_loss: 14.3740 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 2.2894 - accuracy: 0.3941 - val_loss: 14.5573 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 2.2497 - accuracy: 0.4000 - val_loss: 14.8446 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.2275 - accuracy: 0.3824 - val_loss: 15.0498 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 2.1977 - accuracy: 0.3941 - val_loss: 15.2930 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/150\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 2.1720 - accuracy: 0.4000 - val_loss: 15.4600 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/150\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 2.1509 - accuracy: 0.4118 - val_loss: 15.5749 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/150\n",
            "6/6 [==============================] - 1s 174ms/step - loss: 2.1330 - accuracy: 0.4235 - val_loss: 15.6704 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.1194 - accuracy: 0.3882 - val_loss: 15.8105 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 2.0932 - accuracy: 0.4118 - val_loss: 15.9014 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 2.0776 - accuracy: 0.4118 - val_loss: 16.1206 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 2.0621 - accuracy: 0.4059 - val_loss: 16.2238 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/150\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 2.0399 - accuracy: 0.4118 - val_loss: 16.3073 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 2.0182 - accuracy: 0.4176 - val_loss: 16.4162 - val_accuracy: 0.0741\n",
            "Epoch 113/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.0021 - accuracy: 0.4412 - val_loss: 16.5879 - val_accuracy: 0.0741\n",
            "Epoch 114/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.9917 - accuracy: 0.4706 - val_loss: 16.6806 - val_accuracy: 0.0741\n",
            "Epoch 115/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.9739 - accuracy: 0.4706 - val_loss: 16.7605 - val_accuracy: 0.0741\n",
            "Epoch 116/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.9610 - accuracy: 0.4765 - val_loss: 16.9105 - val_accuracy: 0.0741\n",
            "Epoch 117/150\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.9430 - accuracy: 0.4824 - val_loss: 17.0047 - val_accuracy: 0.0741\n",
            "Epoch 118/150\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.9247 - accuracy: 0.4765 - val_loss: 17.1705 - val_accuracy: 0.0741\n",
            "Epoch 119/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.9077 - accuracy: 0.4882 - val_loss: 17.2602 - val_accuracy: 0.0741\n",
            "Epoch 120/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.8971 - accuracy: 0.4765 - val_loss: 17.3633 - val_accuracy: 0.0741\n",
            "Epoch 121/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.8782 - accuracy: 0.4588 - val_loss: 17.5482 - val_accuracy: 0.0741\n",
            "Epoch 122/150\n",
            "6/6 [==============================] - 1s 112ms/step - loss: 1.8746 - accuracy: 0.4647 - val_loss: 17.6191 - val_accuracy: 0.0741\n",
            "Epoch 123/150\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 1.8566 - accuracy: 0.4824 - val_loss: 17.7537 - val_accuracy: 0.0741\n",
            "Epoch 124/150\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 1.8514 - accuracy: 0.4588 - val_loss: 17.7970 - val_accuracy: 0.0741\n",
            "Epoch 125/150\n",
            "6/6 [==============================] - 1s 176ms/step - loss: 1.8302 - accuracy: 0.4824 - val_loss: 17.8440 - val_accuracy: 0.0741\n",
            "Epoch 126/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.8117 - accuracy: 0.4882 - val_loss: 18.0115 - val_accuracy: 0.0741\n",
            "Epoch 127/150\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 1.7984 - accuracy: 0.5000 - val_loss: 18.1076 - val_accuracy: 0.0741\n",
            "Epoch 128/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.7847 - accuracy: 0.4882 - val_loss: 18.2632 - val_accuracy: 0.0741\n",
            "Epoch 129/150\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 1.7757 - accuracy: 0.4882 - val_loss: 18.2904 - val_accuracy: 0.0741\n",
            "Epoch 130/150\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 1.7583 - accuracy: 0.5000 - val_loss: 18.3573 - val_accuracy: 0.0741\n",
            "Epoch 131/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.7518 - accuracy: 0.5118 - val_loss: 18.4207 - val_accuracy: 0.0741\n",
            "Epoch 132/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.7412 - accuracy: 0.5059 - val_loss: 18.4842 - val_accuracy: 0.0741\n",
            "Epoch 133/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.7295 - accuracy: 0.5059 - val_loss: 18.6272 - val_accuracy: 0.0741\n",
            "Epoch 134/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.7174 - accuracy: 0.5000 - val_loss: 18.7371 - val_accuracy: 0.0741\n",
            "Epoch 135/150\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 1.7026 - accuracy: 0.5059 - val_loss: 18.8660 - val_accuracy: 0.0741\n",
            "Epoch 136/150\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.7052 - accuracy: 0.5176 - val_loss: 18.9615 - val_accuracy: 0.0741\n",
            "Epoch 137/150\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.6918 - accuracy: 0.5059 - val_loss: 18.9418 - val_accuracy: 0.0741\n",
            "Epoch 138/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.6917 - accuracy: 0.5118 - val_loss: 19.2289 - val_accuracy: 0.0741\n",
            "Epoch 139/150\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.6855 - accuracy: 0.4941 - val_loss: 19.1774 - val_accuracy: 0.0741\n",
            "Epoch 140/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.6631 - accuracy: 0.5235 - val_loss: 19.2464 - val_accuracy: 0.0741\n",
            "Epoch 141/150\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.6509 - accuracy: 0.5235 - val_loss: 19.3130 - val_accuracy: 0.0741\n",
            "Epoch 142/150\n",
            "6/6 [==============================] - 1s 145ms/step - loss: 1.6484 - accuracy: 0.5176 - val_loss: 19.3423 - val_accuracy: 0.0741\n",
            "Epoch 143/150\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 1.6426 - accuracy: 0.5235 - val_loss: 19.4655 - val_accuracy: 0.0741\n",
            "Epoch 144/150\n",
            "6/6 [==============================] - 1s 177ms/step - loss: 1.6184 - accuracy: 0.5353 - val_loss: 19.5529 - val_accuracy: 0.0741\n",
            "Epoch 145/150\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 1.6202 - accuracy: 0.5235 - val_loss: 19.5664 - val_accuracy: 0.0741\n",
            "Epoch 146/150\n",
            "6/6 [==============================] - 1s 95ms/step - loss: 1.6110 - accuracy: 0.5353 - val_loss: 19.6505 - val_accuracy: 0.0741\n",
            "Epoch 147/150\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.5931 - accuracy: 0.5235 - val_loss: 19.8004 - val_accuracy: 0.0741\n",
            "Epoch 148/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.5875 - accuracy: 0.5294 - val_loss: 19.7467 - val_accuracy: 0.0741\n",
            "Epoch 149/150\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.5807 - accuracy: 0.5294 - val_loss: 19.8736 - val_accuracy: 0.0741\n",
            "Epoch 150/150\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.5718 - accuracy: 0.5176 - val_loss: 19.9970 - val_accuracy: 0.0741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = 'Saya ingin warna yang elegan'\n",
        "\n",
        "input_text = tokenizer.texts_to_sequences([input_text])\n",
        "input_text = pad_sequences(input_text, maxlen=120, padding=\"post\")\n",
        "\n",
        "predicted_probabilities = model1.predict(input_text)[0]\n",
        "predicted_label = np.argmax(predicted_probabilities)\n",
        "predicted_color1 = label1dic[predicted_label]\n",
        "\n",
        "predicted_probabilities = model2.predict(input_text)[0]\n",
        "predicted_label = np.argmax(predicted_probabilities)\n",
        "predicted_color2 = label2dic[predicted_label]\n",
        "\n",
        "predicted_probabilities = model3.predict(input_text)[0]\n",
        "predicted_label = np.argmax(predicted_probabilities)\n",
        "predicted_color3 = label3dic[predicted_label]\n",
        "\n",
        "predicted_probabilities = model4.predict(input_text)[0]\n",
        "predicted_label = np.argmax(predicted_probabilities)\n",
        "predicted_color4 = label4dic[predicted_label]\n",
        "\n",
        "predicted_probabilities = model5.predict(input_text)[0]\n",
        "predicted_label = np.argmax(predicted_probabilities)\n",
        "predicted_color5 = label5dic[predicted_label]\n",
        "\n",
        "print('\\n')\n",
        "print([[predicted_color1, predicted_color2, predicted_color3, predicted_color4, predicted_color5]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmZUctDqvHwE",
        "outputId": "01cd4c52-9008-4979-bde9-8659f1f6bda3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "\n",
            "[['#E6E6FA', '#333333', '#333333', '#FF6F00', '#FFFFFF']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z_St9-d70a6X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}