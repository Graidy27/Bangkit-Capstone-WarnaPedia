# -*- coding: utf-8 -*-
"""Color_Sentiment_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S83eP6ciz2cb4lr3gl91xZEcLTtCSv_b

# **Proyek Rekomendasi Warna Berdasarkan Inputan User**
Tujuan dari proyek ini adalah untuk membuat sebuah model yang dapat memprediksi warna yang dapat direkomendasikan dari inputan user, untuk warna yang ada berjumlah 42 karena dataset ini dibuat oleh saya sendiri dan dibantu juga dari chatGPT. Dataset tersebut berisi kumpulan kata yang labelnya adalah sebuah warna dengan bentuk hexcode.
"""

import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

"""## 1. Load Dataset"""

# Baca dataset
dataset = pd.read_csv("/content/drive/MyDrive/Dataset/color_dataset2.csv")

dataset.head()

dataset.info()

"""Berdasarkan keterangan di atas diketahui bahwa dataset yang digunakan terdiri dari 225 data dan tidak terdapat *missing value*.

## 2. Preprocessing Data

2.1 Mengubah seluruh text kedalam bentuk lowercase
"""

dataset['text'] = dataset['text'].str.lower()
dataset.head()

"""2.2 Menghilangkan stopwords"""

import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

stop_word = set(stopwords.words('indonesian'))
dataset['text'] = dataset['text'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop_word)]))
dataset.head()

# Bagi dataset menjadi data fitur (X) dan label (y)
X = dataset["text"]
y = dataset[["hex_1","hex_2","hex_3","hex_4","hex_5"]]

# Encoding label dengan one-hot encoding
labels = pd.get_dummies(y)

# Bagi dataset menjadi data pelatihan dan data pengujian dengan rasio 80:20
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=123)

# Melihat jumlah data pada data train dan test
print(X_train.shape)
print(X_test.shape)

"""2.3 Membuat tokenisasi"""

filt = '!"#$%&()*+.,-/:;=?@[\]^_`{|}~ ' # Untuk menghilangkan symbols
tokenizer = Tokenizer(num_words=2000, oov_token="<OOV>", filters=filt)
tokenizer.fit_on_texts(X_train)

word_index = tokenizer.word_index
print(len(word_index))

"""2.4 Membuat sequences dan melakukan padding"""

train_sekuens = tokenizer.texts_to_sequences(X_train)
test_sekuens = tokenizer.texts_to_sequences(X_test)


train_padded = pad_sequences(train_sekuens, 
                             maxlen=20,
                             padding='post',
                             truncating='post')
test_padded = pad_sequences(test_sekuens,
                            maxlen=20,
                            padding='post',
                            truncating='post')

train_padded.shape

test_padded.shape

"""## 3. Implementasi Model Dengan Arsitektur LSTM"""

# Membangun model
model = Sequential()
model.add(Embedding(2000, 100, input_length=20))
model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(64, activation="relu"))
model.add(Dropout(0.5))
model.add(Dense(labels.shape[1], activation="softmax"))

model.summary()

model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

"""3.1 Latih model"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs = {}):
    if(logs.get('val_accuracy') > 0.90 and logs.get('accuracy') > 0.90):
      print("\nPELATIHAN BERHENTI, AKURASI MODEL SUDAH LEBIH DARI 90%!")
      self.model.stop_training = True

callbacks = myCallback()

# Melatih model
model.fit(train_padded, y_train, 
          epochs=500, 
          validation_data=(test_padded, y_test),
          verbose=2,
          callbacks=[callbacks])

# Melakukan vektorisasi untuk mengekstrak fitur dengan TF-IDF
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer

vectorizer = TfidfVectorizer(min_df = 5,
                             max_df = 0.8,
                             sublinear_tf = True,
                             use_idf = True)
 
train_vectors = vectorizer.fit_transform(dataset['text'])
test_vectors = vectorizer.transform(dataset['text'])

from sklearn.multioutput import MultiOutputClassifier
from sklearn.svm import SVC

classifier = MultiOutputClassifier(SVC(kernel='linear'))
classifier.fit(train_vectors, dataset[["hex_1","hex_2","hex_3","hex_4","hex_5"]])
predictions = classifier.predict(test_vectors)

teks = """tolong kasih aku warna yang bikin tenang"""
# teks = """kasih aku warna elegan"""
teks_vector = vectorizer.transform([teks]) # vectorizing
print(classifier.predict(teks_vector))

"""## Save Model"""

import joblib

joblib.dump(classifier, 'recommendation_color_model.pkl')

# Memuat model dari file
loaded_classifier = joblib.load('/content/recommendation_color_model.pkl')

# Melakukan prediksi dengan model yang dimuat
predictions = loaded_classifier.predict(test_vectors)
predictions